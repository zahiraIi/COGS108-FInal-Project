<<<<<<< HEAD
## Rubric

Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. 

Scoring: Out of 10 points

- Each Developing  => -2 pts
- Each Unsatisfactory/Missing => -4 pts
  - until the score is 

If students address the detailed feedback in a future checkpoint they will earn these points back


|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |
|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|
| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |
| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |
| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |

# COGS 108 - Data Checkpoint
## Authors

Omar Abbasi: Project Administration, Conceptualization, Formal Analysis, Visualization, Writing â€“ Original Draft  
Zahir Ali: Conceptualization, Visualization, Software, Writing â€“ Reviewing/Edits  
Adam Hamadene: Research, Formal Analysis  
Mostafa Darwish: Visualization, Writing â€“ Original Draft, Data Curation  
Yasir Rizvi: Data Cleaning 

## Research Question
How do funding size, industry sector, and geographic location influence both the likelihood and timing of startup failure versus acquisition?


## Background and Prior Work
As the world continues to see the intersection of human ingenuity and technological accumulation grow extremely rapidly, this shift in the corporate landscape can be tied back to a specific niche: the prevalence and growth of startups in the post-modern era. As technical knowledge and tools continue to develop, human ingenuity has found itself employed in finding the most useful ways to leverage and expand upon the current era of technology and artificial intelligence. Examples of post-modern startups include Uber, Robinhood, Stripe, Databricks, Canva, and Slack. Ideas for growth and innovation stem from all fields, and are catalyzed from a variety of sources such as corporate America, educational insititutions, and small communities all across the country. However, although the majority of the startups known today are those that found success in climbing the barrier between idea and impact, it is the majority that fall short of overcoming this hurdle and end up failing as a product. In this report, we aim to look at a multitude of variables directly and intrinsically tied to startups and their growth, to determine the coefficient of correlation between various factors such as industry sector, funding, location, and size, and how they impact a startup's ability to come to fruition. Because the growth of startups is relatively new and tied to very modern technological advancements, there is a scarce amount of research done into the causes behind their success and failures. For example, venture capital firms and startup accelerators such as Y Combinator were founded in 2005, making the funding rounds for successful startups a very new principle. Our curiosity lies in looking at the underlying details of the successes and failures for startups in the United States, as it provides an opportunity to discover findings in a modern niche that does not possess the level of academic study that other corporate fields in America do.

## Hypothesis

Startups with larger funding sizes, operating in high-growth industry sectors, and located within established entrepreneurial ecosystems are less likely to fail and tend to experience longer survival times before either failure or acquisition, whereas startups with smaller funding, in low-growth sectors, or in emerging regions face higher failure risks and shorter time-to-event durations. 

## Data
### Data overview

- **Dataset #1**
- **Dataset Name**: Startup Success Prediction
  - **Link to the dataset**: 'https://www.kaggle.com/datasets/manishkc06/startup-success-prediction/data'
  - **Number of observations**: 922 
  - **Number of variables**: 49 
  - **Most relevant variables for our project**:
    - Name/ID: name (entity key used for de-duplication)
    - Industry/Sector: labels (needs standardization to top-level sector groups)
    - Geography: e.g., city, state_code (normalize to country/region for stratification)
    - Funding: e.g., funding_total_usd, first_funding_at, last_funding_at, funding_rounds (USD; heavy-tailed; consider log/winsorization)
    - Outcome/Status: status (map to success/failure/censored)
    - Timing: founded_at, closed_at (parsed to datetime for time to event metrics)
  - **Shortcomings / caveats**:
    - Sector taxonomy in labels is noisy; requires collapsing to a consistent hierarchy
    - Coverage/selection bias (by region/state/stage) likely; report as limitation and consider cohort/time controls
    - Event labeling: status may lag reality; treat "operating" as censored in survival framing
    - Date gaps: Missing founded_at/closed_at can bias time-to-event; document drop/impute rules


- **Dataset #2**
  - **Dataset Name**: Big Startup Success/Fail Dataset from Crunchbase
  - **Link to the dataset**: `https://www.kaggle.com/datasets/yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase`
  - **Number of observations**: Computed in the code cell below (after loading)
  - **Number of variables**: Computed in the code cell below (after loading)
  - **Most relevant variables for our project**:
    - Funding-related: `funding_total_usd` (or similar), `funding_rounds`, `last_funding_at`
    - Outcome/status: `status` (e.g., acquired/ipo/operating/closed), `acquired_at`, `closed_at`
    - Company profile: `name`, `category`/`industry`, `country`, `region`/`city`, `num_employees`
    - Timing: `founded_at` (and event dates as above) for computing time-to-failure or time-to-acquisition
  - **Shortcomings / caveats**:
    - Potential label noise: outcomes may be simplified; â€œoperatingâ€ does not guarantee long-term success; â€œclosedâ€ labels may lag reality
    - Missing or inconsistent dates across companies, which affects survival/time-to-event analyses
    - Possible duplicates or multiple rows for the same company over time; category/industry taxonomy can be messy
    - Survivorship and reporting bias inherent to Crunchbase; geographic and sector coverage is uneven

If we combine datasets, we will align on common keys (e.g., standardized company names and/or website domains), and normalize geography (country/region) and industry taxonomies before joining.
# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules
#
## this code is necessary for making sure that any modules we load are updated here 
## when their source code .py files are modified

%load_ext autoreload
%autoreload 2
# Setup code: Data Pre-Download Required

> **Note:** This project requires you to manually download both datasets (as CSVs) from Kaggle and place them in `data/00-raw/`.
>
> - `dataset1.csv` (Startup Success Prediction)  
>   https://www.kaggle.com/datasets/manishkc06/startup-success-prediction
> - `dataset2.csv` (Crunchbase Success/Fail)  
>   https://www.kaggle.com/datasets/yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase
>
> See the project README for detailed instructions.

Once the files are present, run the remaining cells to process and analyze the data.

### Dataset #1 â€” Startup Attributes & Sectors (Uploaded File)

- **What it is**: 922 startups Ã— 49 columns with identity, sector tags, geography, funding, timing, and status.
- **Why it matters**: Complements Crunchbase outcomes; gives clean attributes for joining and modeling.
- **Key fields**: `name`, `labels` (sector), `city`, `state_code`, `funding_total_usd`, `funding_rounds`, `first_funding_at`, `last_funding_at`, `founded_at`, `closed_at`, `status`.
- **Quality notes**: Some sector and date noise; mild geographic imbalance; heavyâ€‘tailed funding.
- **Usage**: Feature engineering and crossâ€‘dataset join keys; baseline EDA on funding/sector/location.

# Dataset #1 â€” Load, Tidy, Profile, and Clean
import pandas as pd
import numpy as np
from pathlib import Path

RAW_DIR = Path("data/00-raw")
INTERIM_DIR = Path("data/01-interim")
PROCESSED_DIR = Path("data/02-processed")
for d in [RAW_DIR, INTERIM_DIR, PROCESSED_DIR]:
    d.mkdir(parents=True, exist_ok=True)

raw_path = RAW_DIR / "dataset1.csv"  
df = pd.read_csv(raw_path)
print(f"âœ… Loaded dataset from: {raw_path}")


df.columns = (
    df.columns.str.strip()
    .str.replace(" ", "_")
    .str.replace("-", "_")
    .str.replace("/", "_")
    .str.replace(".", "_")
    .str.lower()
)


print(f"Shape (rows, columns): {df.shape}")


print(f"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns.")


missing_pct = (df.isna().mean() * 100).round(1).sort_values(ascending=False)
print("\nðŸ” Missingness (% of missing values per column):")
print(missing_pct.head(10))


nan_corr = df.isna().corr()
if nan_corr.shape[0] > 1:
    print("\nTop correlated missingness (possible systematic gaps):")
    corr_pairs = (
        nan_corr.unstack()
        .sort_values(ascending=False)
        .drop_duplicates()
        .head(10)
    )
    print(corr_pairs)

if "funding_total_usd" in df.columns:
    series = pd.to_numeric(df["funding_total_usd"], errors="coerce").dropna()
    if len(series) > 0:
        q1, q3 = np.percentile(series, [25, 75])
        iqr = q3 - q1
        lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr
        df["funding_outlier_flag"] = (
            (df["funding_total_usd"] < lower) | (df["funding_total_usd"] > upper)
        )
        print(
            f"\nðŸ’° Outlier detection for funding_total_usd:\n"
            f"IQR bounds = [{lower:,.0f}, {upper:,.0f}]\n"
            f"Outliers flagged: {df['funding_outlier_flag'].sum()} rows"
        )
    else:
        df["funding_outlier_flag"] = False
else:
    print("\nâš ï¸ No 'funding_total_usd' column found for outlier analysis.")
    df["funding_outlier_flag"] = False

before = len(df)
df = df.drop_duplicates()
if {"name", "status"}.issubset(df.columns):
    df = df.dropna(subset=["name", "status"], how="all")
print(f"\nðŸ§¹ Cleaned dataset: {before} -> {len(df)} rows after cleaning.")

important_vars = [c for c in ["funding_total_usd", "funding_rounds", "status", "city", "state_code"] if c in df.columns]
print("\nðŸ“Š Summary statistics for key variables:")
print(df[important_vars].describe(include="all").transpose().iloc[:10])

processed_path = PROCESSED_DIR / "dataset1_startup_data_processed.csv"
df.to_csv(processed_path, index=False)
print(f"\nâœ… Cleaned dataset saved to: {processed_path}")



### Dataset #2 â€” Crunchbase Startup Outcomes (Failure vs. Acquisition)

- **What it is**: ~66k startups with profile, funding history, geography, and outcome labels (`operating`, `acquired`, `ipo`, `closed`).
- **Why it matters**: Core table for outcome modeling (success vs. failure) and timeâ€‘toâ€‘event analysis.
- **Key fields**: `name`, `category_list` â†’ `industry_primary`, `country_code`/`state_code`/`region`/`city`, `funding_total_usd`, `funding_rounds`, `first_funding_at`, `last_funding_at`, `founded_at`, `acquired_at`, `closed_at`, `status`.
- **Quality notes**: Heavyâ€‘tailed funding; noisy/heterogeneous categories; some missing/lagged event dates.
- **Usage**: Derive `outcome_label` (success/failure/censored), compute `time_to_event_days`, profile geography/industry, and export cleaned CSV for modeling.

# Crunchbase Startup Success/Fail â€” Load, Clean, Tidy, Wrangle
#
# Notes:
# - Place the Kaggle CSV from the dataset into `data/00-raw/`.
# - If multiple CSVs exist, this cell attempts to auto-detect the most likely file.
# - Adjust `RAW_FILENAME_OVERRIDE` if auto-detection fails.

from __future__ import annotations

from pathlib import Path
from typing import Optional, List, Dict

import pandas as pd
import numpy as np

RAW_DIR = Path("data/00-raw")
INTERIM_DIR = Path("data/01-interim")
PROCESSED_DIR = Path("data/02-processed")

INTERIM_DIR.mkdir(parents=True, exist_ok=True)
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

# If you know the exact filename, set it here; otherwise keep as None
RAW_FILENAME_OVERRIDE: Optional[str] = "dataset2.csv"  # renamed for consistency

# Heuristics for picking likely files
LIKELY_SUBSTRINGS: List[str] = [
    "crunchbase",
    "startup",
    "startups",
    "success",
    "fail",
]


def pick_raw_file(raw_dir: Path, override: Optional[str]) -> Path:
    """Pick the most likely raw CSV file for the Crunchbase dataset.

    Args:
        raw_dir: Directory containing raw files.
        override: Explicit filename if known.

    Returns:
        Path to the selected CSV file.

    Raises:
        FileNotFoundError: If no suitable file is found.
    """
    if override is not None:
        candidate = raw_dir / override
        if candidate.exists():
            return candidate
        raise FileNotFoundError(
            f"Override file not found: {candidate}. Place it in {raw_dir} or update RAW_FILENAME_OVERRIDE."
        )

    csvs = sorted(raw_dir.glob("*.csv"))
    if not csvs:
        raise FileNotFoundError(
            f"No CSV files found in {raw_dir}. Download the Kaggle dataset and place the CSV here."
        )

    # Rank by substring match then by size (descending)
    def score(p: Path) -> tuple[int, int]:
        name = p.name.lower()
        match_score = sum(1 for s in LIKELY_SUBSTRINGS if s in name)
        size_score = p.stat().st_size
        return (match_score, size_score)

    ranked = sorted(csvs, key=score, reverse=True)
    return ranked[0]


raw_path = pick_raw_file(RAW_DIR, RAW_FILENAME_OVERRIDE)
print(f"Selected raw file: {raw_path}")

# Load data
# Use low_memory=False for mixed types, and keep original column names for inspection before standardization
raw_df = pd.read_csv(raw_path, low_memory=False)
print(f"Raw shape: {raw_df.shape}")

# Standardize column names: snake_case
raw_df.columns = (
    raw_df.columns.str.strip().str.replace(" ", "_", regex=False).str.replace("-", "_", regex=False).str.lower()
)

# Basic de-duplication by exact row match and by name if present
if "name" in raw_df.columns:
    before = len(raw_df)
    raw_df = raw_df.drop_duplicates()
    raw_df = raw_df.drop_duplicates(subset=["name"], keep="first")
    print(f"Dropped duplicates -> {before} -> {len(raw_df)} rows")
else:
    raw_df = raw_df.drop_duplicates()

# Identify key columns by fuzzy names
def find_col(candidates: List[str]) -> Optional[str]:
    cols = set(raw_df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None

col_name = find_col(["name", "company", "company_name"])
col_status = find_col(["status", "state", "current_status"])  # typical outcome label
col_funded_total = find_col(["funding_total_usd", "funding_total", "total_funding_usd", "total_funding"])
col_rounds = find_col(["funding_rounds", "num_funding_rounds", "rounds"])
col_category = find_col(["category", "category_list", "industry", "category_groups"])
col_country = find_col(["country", "country_code", "country_iso", "country_name"])
col_state = find_col(["state_code", "state"])
col_region = find_col(["region", "state_region"])  # keep region separate from city
col_city = find_col(["city", "location"])  # prefer explicit city when available
col_founded = find_col(["founded_at", "founded", "founded_date"])  # date-like
col_acquired = find_col(["acquired_at", "acquired", "acquisition_date"])  # date-like
col_closed = find_col(["closed_at", "closed", "closing_date"])  # date-like
col_first_funding = find_col(["first_funding_at", "first_funding_date"])  # date-like
col_last_funding = find_col(["last_funding_at", "last_funding_date"])  # date-like
col_employees = find_col(["num_employees", "employee_count", "employees"])

# Restrict to relevant columns (retain existing only)
keep_cols: List[str] = [
    c
    for c in [
        col_name,
        col_status,
        col_funded_total,
        col_rounds,
        col_category,
        col_country,
        col_state,
        col_region,
        col_city,
        col_founded,
        col_acquired,
        col_closed,
        col_first_funding,
        col_last_funding,
        col_employees,
    ]
    if c is not None
]

work_df = raw_df[keep_cols].copy()
print(f"Working shape (selected columns): {work_df.shape}")

# Parse dates where present
for dcol in [col_founded, col_acquired, col_closed, col_first_funding, col_last_funding]:
    if dcol is not None and dcol in work_df.columns:
        work_df[dcol] = pd.to_datetime(work_df[dcol], errors="coerce")

# Coerce funding to numeric USD if present
if col_funded_total is not None and col_funded_total in work_df.columns:
    # Remove currency symbols/commas if any
    work_df[col_funded_total] = (
        work_df[col_funded_total]
        .astype(str)
        .str.replace(",", "", regex=False)
        .str.replace("$", "", regex=False)
        .str.strip()
    )
    work_df[col_funded_total] = pd.to_numeric(work_df[col_funded_total], errors="coerce")

# Derive primary industry from category_list-like column
if col_category is not None and col_category in work_df.columns:
    work_df["industry_primary"] = (
        work_df[col_category]
        .astype("string")
        .str.split("|")
        .str[0]
        .str.strip()
    )

# Derive outcome label: success/failure/censored
# success: acquired or IPO; failure: closed; censored: operating/others with no terminal date
def derive_outcome(status_val: Optional[str]) -> Optional[str]:
    if status_val is None or pd.isna(status_val):
        return None
    s = str(status_val).strip().lower()
    if any(tok in s for tok in ["acquired", "ipo"]):
        return "success"
    if "closed" in s:
        return "failure"
    if any(tok in s for tok in ["operating", "active"]):
        return "censored"
    return None

if col_status is not None and col_status in work_df.columns:
    work_df["outcome_label"] = work_df[col_status].map(derive_outcome)
else:
    work_df["outcome_label"] = None

# Time-to-event from founded to first terminal event if present
def pick_event_date(row: pd.Series) -> pd.Timestamp | pd.NaT:
    # prefer acquired/closed dates; else NaT
    acquired_date = row[col_acquired] if col_acquired in row and pd.notna(row[col_acquired]) else pd.NaT
    closed_date = row[col_closed] if col_closed in row and pd.notna(row[col_closed]) else pd.NaT
    # pick whichever is earliest non-NaT
    if pd.notna(acquired_date) and pd.notna(closed_date):
        return min(acquired_date, closed_date)
    if pd.notna(acquired_date):
        return acquired_date
    if pd.notna(closed_date):
        return closed_date
    return pd.NaT

if col_founded is not None and col_founded in work_df.columns:
    work_df["event_date"] = work_df.apply(pick_event_date, axis=1)
    work_df["time_to_event_days"] = (
        work_df["event_date"] - work_df[col_founded]
    ).dt.days
else:
    work_df["event_date"] = pd.NaT
    work_df["time_to_event_days"] = np.nan

# Missingness profile
missing_pct = work_df.isna().mean().sort_values(ascending=False)
print("\nMissingness (% of rows missing per column):")
print((missing_pct * 100).round(1))

# Flag outliers in funding (IQR method)
if col_funded_total is not None and col_funded_total in work_df.columns:
    fund = work_df[col_funded_total].dropna()
    if len(fund) > 0:
        q1, q3 = np.percentile(fund, [25, 75])
        iqr = q3 - q1
        upper = q3 + 1.5 * iqr
        lower = max(0, q1 - 1.5 * iqr)
        work_df["funding_outlier_flag"] = (
            (work_df[col_funded_total] < lower) | (work_df[col_funded_total] > upper)
        )
        print(
            f"Funding IQR bounds -> lower={lower:,.0f}, upper={upper:,.0f}; "
            f"outliers flagged: {work_df['funding_outlier_flag'].sum()}"
        )
    else:
        work_df["funding_outlier_flag"] = False
else:
    work_df["funding_outlier_flag"] = False

# Minimal cleaning: drop rows with no name and no status
min_keep_cols = [c for c in [col_name, col_status] if c is not None]
if min_keep_cols:
    before = len(work_df)
    work_df = work_df.dropna(subset=min_keep_cols, how="all")
    print(f"Dropped rows missing all of {min_keep_cols}: {before} -> {len(work_df)}")

# Save processed
processed_path = PROCESSED_DIR / "startups_crunchbase_processed.csv"
work_df.to_csv(processed_path, index=False)
print(f"\nProcessed file written to: {processed_path}")

# Summary (expanded to reflect all relevant data sources)
summary = {
    "n_rows": len(work_df),
    "n_cols": work_df.shape[1],
    "outcome_counts": work_df["outcome_label"].value_counts(dropna=False).to_dict() if "outcome_label" in work_df else {},
}

if col_funded_total in work_df.columns:
    fund = work_df[col_funded_total]
    summary["funding_total_usd"] = {
        "non_null": int(fund.notna().sum()),
        "mean": float(np.nanmean(fund)),
        "median": float(np.nanmedian(fund)),
        "p90": float(np.nanpercentile(fund.dropna(), 90)) if fund.notna().any() else None,
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Omar Abbasi: Project Administration, Conceptualization, Formal Analysis, Visualization, Writing â€“ Original Draft  \n",
    "Zahir Ali: Conceptualization, Visualization, Software, Writing â€“ Reviewing/Edits  \n",
    "Adam Hamadene: Research, Formal Analysis  \n",
    "Mostafa Darwish: Visualization, Writing â€“ Original Draft, Data Curation  \n",
    "Yasir Rizvi: Data Cleaning \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do funding size, industry sector, and geographic location influence both the likelihood and timing of startup failure versus acquisition?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the world continues to see the intersection of human ingenuity and technological accumulation grow extremely rapidly, this shift in the corporate landscape can be tied back to a specific niche: the prevalence and growth of startups in the post-modern era. As technical knowledge and tools continue to develop, human ingenuity has found itself employed in finding the most useful ways to leverage and expand upon the current era of technology and artificial intelligence. Examples of post-modern startups include Uber, Robinhood, Stripe, Databricks, Canva, and Slack. Ideas for growth and innovation stem from all fields, and are catalyzed from a variety of sources such as corporate America, educational insititutions, and small communities all across the country. However, although the majority of the startups known today are those that found success in climbing the barrier between idea and impact, it is the majority that fall short of overcoming this hurdle and end up failing as a product. In this report, we aim to look at a multitude of variables directly and intrinsically tied to startups and their growth, to determine the coefficient of correlation between various factors such as industry sector, funding, location, and size, and how they impact a startup's ability to come to fruition. Because the growth of startups is relatively new and tied to very modern technological advancements, there is a scarce amount of research done into the causes behind their success and failures. For example, venture capital firms and startup accelerators such as Y Combinator were founded in 2005, making the funding rounds for successful startups a very new principle. Our curiosity lies in looking at the underlying details of the successes and failures for startups in the United States, as it provides an opportunity to discover findings in a modern niche that does not possess the level of academic study that other corporate fields in America do.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Startups with larger funding sizes, operating in high-growth industry sectors, and located within established entrepreneurial ecosystems are less likely to fail and tend to experience longer survival times before either failure or acquisition, whereas startups with smaller funding, in low-growth sectors, or in emerging regions face higher failure risks and shorter time-to-event durations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "- **Dataset Name**: Startup Success Prediction\n",
    "  - **Link to the dataset**: 'https://www.kaggle.com/datasets/manishkc06/startup-success-prediction/data'\n",
    "  - **Number of observations**: 922 \n",
    "  - **Number of variables**: 49 \n",
    "  - **Most relevant variables for our project**:\n",
    "    - Name/ID: name (entity key used for de-duplication)\n",
    "    - Industry/Sector: labels (needs standardization to top-level sector groups)\n",
    "    - Geography: e.g., city, state_code (normalize to country/region for stratification)\n",
    "    - Funding: e.g., funding_total_usd, first_funding_at, last_funding_at, funding_rounds (USD; heavy-tailed; consider log/winsorization)\n",
    "    - Outcome/Status: status (map to success/failure/censored)\n",
    "    - Timing: founded_at, closed_at (parsed to datetime for time to event metrics)\n",
    "  - **Shortcomings / caveats**:\n",
    "    - Sector taxonomy in labels is noisy; requires collapsing to a consistent hierarchy\n",
    "    - Coverage/selection bias (by region/state/stage) likely; report as limitation and consider cohort/time controls\n",
    "    - Event labeling: status may lag reality; treat \"operating\" as censored in survival framing\n",
    "    - Date gaps: Missing founded_at/closed_at can bias time-to-event; document drop/impute rules\n",
    "\n",
    "- **Dataset #2**\n",
    "  - **Dataset Name**: Big Startup Success/Fail Dataset from Crunchbase\n",
    "  - **Link to the dataset**: `https://www.kaggle.com/datasets/yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase`\n",
    "  - **Number of observations**: Computed in the code cell below (after loading)\n",
    "  - **Number of variables**: Computed in the code cell below (after loading)\n",
    "  - **Most relevant variables for our project**:\n",
    "    - Funding-related: `funding_total_usd` (or similar), `funding_rounds`, `last_funding_at`\n",
    "    - Outcome/status: `status` (e.g., acquired/ipo/operating/closed), `acquired_at`, `closed_at`\n",
    "    - Company profile: `name`, `category`/`industry`, `country`, `region`/`city`, `num_employees`\n",
    "    - Timing: `founded_at` (and event dates as above) for computing time-to-failure or time-to-acquisition\n",
    "  - **Shortcomings / caveats**:\n",
    "    - Potential label noise: outcomes may be simplified; â€œoperatingâ€ does not guarantee long-term success; â€œclosedâ€ labels may lag reality\n",
    "    - Missing or inconsistent dates across companies, which affects survival/time-to-event analyses\n",
    "    - Possible duplicates or multiple rows for the same company over time; category/industry taxonomy can be messy\n",
    "    - Survivorship and reporting bias inherent to Crunchbase; geographic and sector coverage is uneven\n",
    "\n",
    "If we combine datasets, we will align on common keys (e.g., standardized company names and/or website domains), and normalize geography (country/region) and industry taxonomies before joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
>>>>>>> 4a940b8 (please god work)
    }
   ],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: airline-safety.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 27.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline\n",
    "\n",
    "### Week 3\n",
    "- **Monday:** Meeting to brainstorm project topics, confirm individual dataset search responsibilities and initiate the plan for our topic.\n",
    "- **Friday:** Zoom meeting to vote on and finalize topic.\n",
    "- **Sunday:** Zoom meeting to discuss roles then consolidate and review the datasets weâ€™ve individually found.\n",
    "\n",
    "### Week 4\n",
    "- **Monday:** Meet in Geisel to consolidate datasets and assign roles for our project proposal. Begin working on data cleaning plan, early transformations, and outline visualization goals.\n",
    "- **Wednesday:** Proofread and finalize proposal.\n",
    "\n",
    "### Week 5\n",
    "- **Monday:** Begin data cleaning and preprocessing our datasets.\n",
    "- **Wednesday:** Continue data cleaning and finalize our structured and processed dataset; share cleaned files with each other.\n",
    "\n",
    "### Week 6\n",
    "- **Sunday:** Zoom meeting to compare our processed datasets and make sure everything is consistent.\n",
    "- **Monday:** Discuss trends and finalize consensus on dataset selection and structure.\n",
    "- **Wednesday:** Complete initial EDA preparation, finalize plan for visualization types.\n",
    "\n",
    "### Week 7\n",
    "- **Monday:** Start building visualizations, assign figure responsibilities to group members.\n",
    "- **Friday:** Review meeting to make sure visualizations are progressing and discuss results and narrative.\n",
    "\n",
    "### Week 8\n",
    "- **Monday:** Compile all visualizations and ensure consistency.\n",
    "- **Wednesday:** Polish everything, ensure code runs cleanly.\n",
    "\n",
    "### Week 9\n",
    "- **Monday:** Final review session, proofread notebook text, verify rubric requirements, and finalize project. Begin preparing video.\n",
    "- **Wednesday:** Submit final project and recording; complete team evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded dataset from: data/00-raw/dataset1.csv\n",
      "Shape (rows, columns): (923, 49)\n",
      "The dataset contains 923 rows and 49 columns.\n",
      "\n",
      "ðŸ” Missingness (% of missing values per column):\n",
      "closed_at                   63.7\n",
      "unnamed:_6                  53.4\n",
      "age_last_milestone_year     16.5\n",
      "age_first_milestone_year    16.5\n",
      "state_code_1                 0.1\n",
      "unnamed:_0                   0.0\n",
      "is_biotech                   0.0\n",
      "is_software                  0.0\n",
      "is_web                       0.0\n",
      "is_mobile                    0.0\n",
      "dtype: float64\n",
      "\n",
      "Top correlated missingness (possible systematic gaps):\n",
      "unnamed:_6                unnamed:_6      1.000000\n",
      "                          closed_at       0.139718\n",
      "                          state_code_1    0.030757\n",
      "age_first_milestone_year  state_code_1   -0.014623\n",
      "closed_at                 state_code_1   -0.043632\n",
      "age_first_milestone_year  unnamed:_6     -0.118216\n",
      "                          closed_at      -0.302727\n",
      "unnamed:_0                unnamed:_0           NaN\n",
      "dtype: float64\n",
      "\n",
      "ðŸ’° Outlier detection for funding_total_usd:\n",
      "IQR bounds = [-30,275,000, 57,725,000]\n",
      "Outliers flagged: 65 rows\n",
      "\n",
      "ðŸ§¹ Cleaned dataset: 923 -> 923 rows after cleaning.\n",
      "\n",
      "ðŸ“Š Summary statistics for key variables:\n",
      "                   count unique            top freq             mean  \\\n",
      "funding_total_usd  923.0    NaN            NaN  NaN  25419749.092091   \n",
      "funding_rounds     923.0    NaN            NaN  NaN         2.310943   \n",
      "status               923      2       acquired  597              NaN   \n",
      "city                 923    221  San Francisco  128              NaN   \n",
      "state_code           923     35             CA  488              NaN   \n",
      "\n",
      "                                std      min        25%         50%  \\\n",
      "funding_total_usd  189634364.488794  11000.0  2725000.0  10000000.0   \n",
      "funding_rounds             1.390922      1.0        1.0         2.0   \n",
      "status                          NaN      NaN        NaN         NaN   \n",
      "city                            NaN      NaN        NaN         NaN   \n",
      "state_code                      NaN      NaN        NaN         NaN   \n",
      "\n",
      "                          75%           max  \n",
      "funding_total_usd  24725000.0  5700000000.0  \n",
      "funding_rounds            3.0          10.0  \n",
      "status                    NaN           NaN  \n",
      "city                      NaN           NaN  \n",
      "state_code                NaN           NaN  \n",
      "\n",
      "âœ… Cleaned dataset saved to: data/02-processed/dataset1_startup_data_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "INTERIM_DIR = Path(\"data/01-interim\")\n",
    "PROCESSED_DIR = Path(\"data/02-processed\")\n",
    "for d in [RAW_DIR, INTERIM_DIR, PROCESSED_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "raw_path = RAW_DIR / \"dataset1.csv\"  \n",
    "df = pd.read_csv(raw_path)\n",
    "print(f\"âœ… Loaded dataset from: {raw_path}\")\n",
    "\n",
    "\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\"-\", \"_\")\n",
    "    .str.replace(\"/\", \"_\")\n",
    "    .str.replace(\".\", \"_\")\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Shape (rows, columns): {df.shape}\")\n",
    "\n",
    "\n",
    "print(f\"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "\n",
    "missing_pct = (df.isna().mean() * 100).round(1).sort_values(ascending=False)\n",
    "print(\"\\nðŸ” Missingness (% of missing values per column):\")\n",
    "print(missing_pct.head(10))\n",
    "\n",
    "\n",
    "nan_corr = df.isna().corr()\n",
    "if nan_corr.shape[0] > 1:\n",
    "    print(\"\\nTop correlated missingness (possible systematic gaps):\")\n",
    "    corr_pairs = (\n",
    "        nan_corr.unstack()\n",
    "        .sort_values(ascending=False)\n",
    "        .drop_duplicates()\n",
    "        .head(10)\n",
    "    )\n",
    "    print(corr_pairs)\n",
    "\n",
    "if \"funding_total_usd\" in df.columns:\n",
    "    series = pd.to_numeric(df[\"funding_total_usd\"], errors=\"coerce\").dropna()\n",
    "    if len(series) > 0:\n",
    "        q1, q3 = np.percentile(series, [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "        df[\"funding_outlier_flag\"] = (\n",
    "            (df[\"funding_total_usd\"] < lower) | (df[\"funding_total_usd\"] > upper)\n",
    "        )\n",
    "        print(\n",
    "            f\"\\nðŸ’° Outlier detection for funding_total_usd:\\n\"\n",
    "            f\"IQR bounds = [{lower:,.0f}, {upper:,.0f}]\\n\"\n",
    "            f\"Outliers flagged: {df['funding_outlier_flag'].sum()} rows\"\n",
    "        )\n",
    "    else:\n",
    "        df[\"funding_outlier_flag\"] = False\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No 'funding_total_usd' column found for outlier analysis.\")\n",
    "    df[\"funding_outlier_flag\"] = False\n",
    "\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "if {\"name\", \"status\"}.issubset(df.columns):\n",
    "    df = df.dropna(subset=[\"name\", \"status\"], how=\"all\")\n",
    "print(f\"\\nðŸ§¹ Cleaned dataset: {before} -> {len(df)} rows after cleaning.\")\n",
    "\n",
    "important_vars = [c for c in [\"funding_total_usd\", \"funding_rounds\", \"status\", \"city\", \"state_code\"] if c in df.columns]\n",
    "print(\"\\nðŸ“Š Summary statistics for key variables:\")\n",
    "print(df[important_vars].describe(include=\"all\").transpose().iloc[:10])\n",
    "\n",
    "processed_path = PROCESSED_DIR / \"dataset1_startup_data_processed.csv\"\n",
    "df.to_csv(processed_path, index=False)\n",
    "print(f\"\\nâœ… Cleaned dataset saved to: {processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 â€” Crunchbase Startup Outcomes (Failure vs. Acquisition)\n",
    "\n",
    "This dataset contains company-level records from Crunchbase with profile attributes (name, industry/category), geography (country, region/city), funding history (total USD raised, number of rounds, last funding date), and outcome indicators (operating, acquired, IPO, closed) with event timestamps. It directly supports our hypothesis by enabling both:\n",
    "\n",
    "- Likelihood modeling: whether a startup ultimately fails (closed) or is successfully exited (acquired/IPO).\n",
    "- Timing modeling: how long it takes from founding to failure vs. acquisition (time-to-event).\n",
    "\n",
    "Scope and variables aligned to the hypothesis:\n",
    "- **Funding size and intensity**: `funding_total_usd` (USD, heavyâ€‘tailed), `funding_rounds` (count), `last_funding_at` (recency control).\n",
    "- **Industry sector**: `category`/`industry`/`category_list` (will standardize to a consistent taxonomy and allow multi-label handling when needed).\n",
    "- **Geographic location**: `country`/`country_code`, `region`/`city` (we will normalize to country and, when available, region for stratification).\n",
    "- **Outcomes and timing**: `status` plus event dates `acquired_at`, `closed_at`, and baseline `founded_at` to compute durations.\n",
    "\n",
    "Outcome coding and analysis framing:\n",
    "- **Success**: acquired or IPO.\n",
    "- **Failure**: closed.\n",
    "- **Censored**: operating/active at last observation (no terminal event yet).\n",
    "- We will treat timing via survival/competingâ€‘risks framing: time from `founded_at` to first terminal event (acquisition or closure), censoring otherwise. This supports estimating how funding, sector, and geography shift both hazards and ultimate probabilities.\n",
    "\n",
    "Key data characteristics and handling notes:\n",
    "- **Heavy tails in funding**: consider log1p transform or winsorization; flag extreme outliers for sensitivity checks.\n",
    "- **Sector taxonomy**: categories are noisy/inconsistent; we will collapse to a manageable hierarchy (e.g., topâ€‘level sector groups).\n",
    "- **Geographic normalization**: standardize country codes; map regions/cities to country, and use region only when coverage is sufficient.\n",
    "- **Missingness**: dates and categories can be absent; we will profile missingness, document imputation/dropping rules, and avoid introducing informative censoring.\n",
    "- **Entity resolution**: deâ€‘duplicate by exact rows and harmonized `name`; spotâ€‘check ambiguous entities.\n",
    "- **Coverage bias**: Crunchbase coverage varies by sector, geography, and stage; we will include cohort/time fixed effects where needed and report limitations.\n",
    "\n",
    "Wrangling plan(TBD, can be altered...):\n",
    "- Load from `data/00-raw/`, standardize column names and types, parse dates, harmonize sector and geography, derive `outcome_label` and `time_to_event_days`, flag funding outliers, and export an analysisâ€‘ready file to `data/02-processed/` for modeling likelihood and timing of failure vs. acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected raw file: data/00-raw/dataset2.csv\n",
      "Raw shape: (66368, 14)\n",
      "Dropped duplicates -> 66368 -> 66103 rows\n",
      "Working shape (selected columns): (66103, 9)\n",
      "\n",
      "Missingness (% of rows missing per column):\n",
      "event_date            100.0\n",
      "time_to_event_days    100.0\n",
      "founded_at             22.9\n",
      "funding_total_usd      19.2\n",
      "region                 12.1\n",
      "country_code           10.5\n",
      "category_list           4.7\n",
      "name                    0.0\n",
      "status                  0.0\n",
      "funding_rounds          0.0\n",
      "last_funding_at         0.0\n",
      "outcome_label           0.0\n",
      "dtype: float64\n",
      "Funding IQR bounds -> lower=0, upper=24,495,250; outliers flagged: 7363\n",
      "Dropped rows missing all of ['name', 'status']: 66103 -> 66103\n",
      "\n",
      "Processed file written to: data/02-processed/startups_crunchbase_processed.csv\n",
      "\n",
      "Summary:\n",
      "{'n_rows': 66103, 'n_cols': 13, 'outcome_counts': {'censored': 52812, 'success': 7088, 'failure': 6203}}\n"
     ]
    }
   ],
   "source": [
    "# Crunchbase Startup Success/Fail â€” Load, Clean, Tidy, Wrangle\n",
    "#\n",
    "# Notes:\n",
    "# - Place the Kaggle CSV from the dataset into `data/00-raw/`.\n",
    "# - If multiple CSVs exist, this cell attempts to auto-detect the most likely file.\n",
    "# - Adjust `RAW_FILENAME_OVERRIDE` if auto-detection fails.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "INTERIM_DIR = Path(\"data/01-interim\")\n",
    "PROCESSED_DIR = Path(\"data/02-processed\")\n",
    "\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you know the exact filename, set it here; otherwise keep as None\n",
    "RAW_FILENAME_OVERRIDE: Optional[str] = \"dataset2.csv\"  # renamed for consistency\n",
    "\n",
    "# Heuristics for picking likely files\n",
    "LIKELY_SUBSTRINGS: List[str] = [\n",
    "    \"crunchbase\",\n",
    "    \"startup\",\n",
    "    \"startups\",\n",
    "    \"success\",\n",
    "    \"fail\",\n",
    "]\n",
    "\n",
    "\n",
    "def pick_raw_file(raw_dir: Path, override: Optional[str]) -> Path:\n",
    "    \"\"\"Pick the most likely raw CSV file for the Crunchbase dataset.\n",
    "\n",
    "    Args:\n",
    "        raw_dir: Directory containing raw files.\n",
    "        override: Explicit filename if known.\n",
    "\n",
    "    Returns:\n",
    "        Path to the selected CSV file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no suitable file is found.\n",
    "    \"\"\"\n",
    "    if override is not None:\n",
    "        candidate = raw_dir / override\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        raise FileNotFoundError(\n",
    "            f\"Override file not found: {candidate}. Place it in {raw_dir} or update RAW_FILENAME_OVERRIDE.\"\n",
    "        )\n",
    "\n",
    "    csvs = sorted(raw_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No CSV files found in {raw_dir}. Download the Kaggle dataset and place the CSV here.\"\n",
    "        )\n",
    "\n",
    "    # Rank by substring match then by size (descending)\n",
    "    def score(p: Path) -> tuple[int, int]:\n",
    "        name = p.name.lower()\n",
    "        match_score = sum(1 for s in LIKELY_SUBSTRINGS if s in name)\n",
    "        size_score = p.stat().st_size\n",
    "        return (match_score, size_score)\n",
    "\n",
    "    ranked = sorted(csvs, key=score, reverse=True)\n",
    "    return ranked[0]\n",
    "\n",
    "\n",
    "raw_path = pick_raw_file(RAW_DIR, RAW_FILENAME_OVERRIDE)\n",
    "print(f\"Selected raw file: {raw_path}\")\n",
    "\n",
    "# Load data\n",
    "# Use low_memory=False for mixed types, and keep original column names for inspection before standardization\n",
    "raw_df = pd.read_csv(raw_path, low_memory=False)\n",
    "print(f\"Raw shape: {raw_df.shape}\")\n",
    "\n",
    "# Standardize column names: snake_case\n",
    "raw_df.columns = (\n",
    "    raw_df.columns.str.strip().str.replace(\" \", \"_\", regex=False).str.replace(\"-\", \"_\", regex=False).str.lower()\n",
    ")\n",
    "\n",
    "# Basic de-duplication by exact row match and by name if present\n",
    "if \"name\" in raw_df.columns:\n",
    "    before = len(raw_df)\n",
    "    raw_df = raw_df.drop_duplicates()\n",
    "    raw_df = raw_df.drop_duplicates(subset=[\"name\"], keep=\"first\")\n",
    "    print(f\"Dropped duplicates -> {before} -> {len(raw_df)} rows\")\n",
    "else:\n",
    "    raw_df = raw_df.drop_duplicates()\n",
    "\n",
    "# Identify key columns by fuzzy names\n",
    "def find_col(candidates: List[str]) -> Optional[str]:\n",
    "    cols = set(raw_df.columns)\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "col_name = find_col([\"name\", \"company\", \"company_name\"])\n",
    "col_status = find_col([\"status\", \"state\", \"current_status\"])  # typical outcome label\n",
    "col_funded_total = find_col([\"funding_total_usd\", \"funding_total\", \"total_funding_usd\", \"total_funding\"])\n",
    "col_rounds = find_col([\"funding_rounds\", \"num_funding_rounds\", \"rounds\"])\n",
    "col_category = find_col([\"category\", \"category_list\", \"industry\", \"category_groups\"])\n",
    "col_country = find_col([\"country\", \"country_code\", \"country_iso\", \"country_name\"])\n",
    "col_region = find_col([\"region\", \"state_region\", \"state\", \"city\", \"location\"])\n",
    "col_founded = find_col([\"founded_at\", \"founded\", \"founded_date\"])  # date-like\n",
    "col_acquired = find_col([\"acquired_at\", \"acquired\", \"acquisition_date\"])  # date-like\n",
    "col_closed = find_col([\"closed_at\", \"closed\", \"closing_date\"])  # date-like\n",
    "col_last_funding = find_col([\"last_funding_at\", \"last_funding_date\"])  # date-like\n",
    "col_employees = find_col([\"num_employees\", \"employee_count\", \"employees\"])\n",
    "\n",
    "# Restrict to relevant columns (retain existing only)\n",
    "keep_cols: List[str] = [\n",
    "    c\n",
    "    for c in [\n",
    "        col_name,\n",
    "        col_status,\n",
    "        col_funded_total,\n",
    "        col_rounds,\n",
    "        col_category,\n",
    "        col_country,\n",
    "        col_region,\n",
    "        col_founded,\n",
    "        col_acquired,\n",
    "        col_closed,\n",
    "        col_last_funding,\n",
    "        col_employees,\n",
    "    ]\n",
    "    if c is not None\n",
    "]\n",
    "\n",
    "work_df = raw_df[keep_cols].copy()\n",
    "print(f\"Working shape (selected columns): {work_df.shape}\")\n",
    "\n",
    "# Parse dates where present\n",
    "for dcol in [col_founded, col_acquired, col_closed, col_last_funding]:\n",
    "    if dcol is not None and dcol in work_df.columns:\n",
    "        work_df[dcol] = pd.to_datetime(work_df[dcol], errors=\"coerce\")\n",
    "\n",
    "# Coerce funding to numeric USD if present\n",
    "if col_funded_total is not None and col_funded_total in work_df.columns:\n",
    "    # Remove currency symbols/commas if any\n",
    "    work_df[col_funded_total] = (\n",
    "        work_df[col_funded_total]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\", regex=False)\n",
    "        .str.replace(\"$\", \"\", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    work_df[col_funded_total] = pd.to_numeric(work_df[col_funded_total], errors=\"coerce\")\n",
    "\n",
    "# Derive outcome label: success/failure/censored\n",
    "# success: acquired or IPO; failure: closed; censored: operating/others with no terminal date\n",
    "def derive_outcome(status_val: Optional[str]) -> Optional[str]:\n",
    "    if status_val is None or pd.isna(status_val):\n",
    "        return None\n",
    "    s = str(status_val).strip().lower()\n",
    "    if any(tok in s for tok in [\"acquired\", \"ipo\"]):\n",
    "        return \"success\"\n",
    "    if \"closed\" in s:\n",
    "        return \"failure\"\n",
    "    if any(tok in s for tok in [\"operating\", \"active\"]):\n",
    "        return \"censored\"\n",
    "    return None\n",
    "\n",
    "if col_status is not None and col_status in work_df.columns:\n",
    "    work_df[\"outcome_label\"] = work_df[col_status].map(derive_outcome)\n",
    "else:\n",
    "    work_df[\"outcome_label\"] = None\n",
    "\n",
    "# Time-to-event from founded to first terminal event if present\n",
    "def pick_event_date(row: pd.Series) -> pd.Timestamp | pd.NaT:\n",
    "    # prefer acquired/closed dates; else NaT\n",
    "    acquired_date = row[col_acquired] if col_acquired in row and pd.notna(row[col_acquired]) else pd.NaT\n",
    "    closed_date = row[col_closed] if col_closed in row and pd.notna(row[col_closed]) else pd.NaT\n",
    "    # pick whichever is earliest non-NaT\n",
    "    if pd.notna(acquired_date) and pd.notna(closed_date):\n",
    "        return min(acquired_date, closed_date)\n",
    "    if pd.notna(acquired_date):\n",
    "        return acquired_date\n",
    "    if pd.notna(closed_date):\n",
    "        return closed_date\n",
    "    return pd.NaT\n",
    "\n",
    "if col_founded is not None and col_founded in work_df.columns:\n",
    "    work_df[\"event_date\"] = work_df.apply(pick_event_date, axis=1)\n",
    "    work_df[\"time_to_event_days\"] = (\n",
    "        work_df[\"event_date\"] - work_df[col_founded]\n",
    "    ).dt.days\n",
    "else:\n",
    "    work_df[\"event_date\"] = pd.NaT\n",
    "    work_df[\"time_to_event_days\"] = np.nan\n",
    "\n",
    "# Missingness profile\n",
    "missing_pct = work_df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nMissingness (% of rows missing per column):\")\n",
    "print((missing_pct * 100).round(1))\n",
    "\n",
    "# Flag outliers in funding (IQR method)\n",
    "if col_funded_total is not None and col_funded_total in work_df.columns:\n",
    "    fund = work_df[col_funded_total].dropna()\n",
    "    if len(fund) > 0:\n",
    "        q1, q3 = np.percentile(fund, [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        lower = max(0, q1 - 1.5 * iqr)\n",
    "        work_df[\"funding_outlier_flag\"] = (\n",
    "            (work_df[col_funded_total] < lower) | (work_df[col_funded_total] > upper)\n",
    "        )\n",
    "        print(\n",
    "            f\"Funding IQR bounds -> lower={lower:,.0f}, upper={upper:,.0f}; \"\n",
    "            f\"outliers flagged: {work_df['funding_outlier_flag'].sum()}\"\n",
    "        )\n",
    "    else:\n",
    "        work_df[\"funding_outlier_flag\"] = False\n",
    "else:\n",
    "    work_df[\"funding_outlier_flag\"] = False\n",
    "\n",
    "# Minimal cleaning: drop rows with no name and no status\n",
    "min_keep_cols = [c for c in [col_name, col_status] if c is not None]\n",
    "if min_keep_cols:\n",
    "    before = len(work_df)\n",
    "    work_df = work_df.dropna(subset=min_keep_cols, how=\"all\")\n",
    "    print(f\"Dropped rows missing all of {min_keep_cols}: {before} -> {len(work_df)}\")\n",
    "\n",
    "# Save processed\n",
    "processed_path = PROCESSED_DIR / \"startups_crunchbase_processed.csv\"\n",
    "work_df.to_csv(processed_path, index=False)\n",
    "print(f\"\\nProcessed file written to: {processed_path}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nSummary:\")\n",
    "print({\n",
    "    \"n_rows\": len(work_df),\n",
    "    \"n_cols\": work_df.shape[1],\n",
    "    \"outcome_counts\": work_df[\"outcome_label\"].value_counts(dropna=False).to_dict() if \"outcome_label\" in work_df else {},\n",
    "})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bias & fairness:** Datasets may favor startups or sectors that are much higher in popularity and show a bias towards well known startups. There are also concerns with issues of generlzation as some areas may have high density of startups compared to others potential misrepresenting the data.\n",
    "- **Generalization limits:** As mentioned previously, Kaggle datasets in particular may overrepresent high success startups due to the ease of accessing the data. This results in the data not geenrlazaing to non-tech or smaller companies. We intend to avoid general claims and make specifc statements that are contextualized by environment maturity.\n",
    "- **Data sensitivity:** Although the data gathered is public, names and emails can be used to reidenifty an individual, or any specific data points that can be used to triangulate a person or startup.Â \n",
    "- **Non-Consensual Use of Company Information:** Despite the data being public, startups in the dataset did not consent to be analyzed or used for prediction exercises. We will be using aggregated analysis and not single out any companies.\n",
    "- **Potential Misrepresentation Due to Inaccurate or Incomplete Data:** Startup databases are often incomplete, outdated, or wrong because the data is crowdsourced. We will treat the data as approximate and emphasize uncertainty rather than presenting results as definitive truth.\n",
    "- **Responsibility to Prevent Harmful Use of Results:** If someone misuses the findings it may influence funding or hiring decisions, or perceptions of certain industries/regions. We will explicitly state that the work should not be used for investment decisions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regards to communication, we plan on using iMessage to text one another. We believe this is one of the most efficient and easiest ways for us to contact one another. As for the ,essaging itself, all members have agreed to expect a rresponse, whether that be a message or a reaction, from each group member within 3 hours of the initial text being sent. We will meet twice per week, every Monday morning we will reserve a study space in the Geisel Library to meet and prodvide updates, followed by a Zoom meetimng every Friday afternoon to consolidate the designated progress from Onday's meeting. In regarcs to tone, we agree to all expect respectful interactions. Even when disagreement takes place, the person expressing the lack of approval should explain their reasonibg, as well as an alkternative method that they beleive is better. We will be concise and to the point, but still maintaining respect for one another and everyone's ideas. We plan to use voting to make decisions as a group, especially for disagreements and changes to our original plan. The project administrator will be in charge of calling teh vote, ad we will go with the majority ruling, as wel have3 5 people. We will not accept abstaining from votes. We do have specialized roles for each person, hwoever, because there is overlap, we do plan to share a lot of the responsibilties. As we are a team, we plan on heloing each other out when possible, especially if one person is struggling with a specific task. We assign roles and tasks based on the skillsets of the members, which we have laready discussed in detail. We have set a policy that struggles are inevitbale, as we are all busy. We have a guideline that whenever someone is falling behind, there is no hassle or problem in expressing that as early as possible. We would rather know what to fix earlier on in the process, rather than have a last minute lack of execution. Struggles with certain tasks hoild be expressd immediately, as we will set egos aside ti help regardless of role/assignned tasks, in roder to priotitize the team as a unit/whole.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline\n",
    "### Week 3\n",
    "- **Monday:** Meeting to brainstorm project topics, confirm individual dataset search responsibilities and initiate the plan for our topic.\n",
    "- **Friday:** Zoom meeting to vote on and finalize topic.,\n",
    "- **Sunday:** Zoom meeting to discuss roles then consolidate and review the datasets weâ€™ve individually found.\n",
    "\n",
    "### Week 4\n",
    "- **Monday:** Meet in Geisel to consolidate datasets and assign roles for our project proposal. Begin working on data cleaning plan, early transformations, and outline visualization goals.\n",
    "- **Wednesday:** Proofread and finalize proposal\n",
    "\n",
    "\n",
    "### Week 5,\n",
    "- **Monday:** Begin data cleaning and preprocessing our datasets.\n",
    "- **Wednesday:** Continue data cleaning and finalize our structured and processed dataset; share cleaned files with each other.\n",
    "\n",
    "### Week 6\n",
    "- **Sunday:** Zoom meeting to compare our processed datasets and make sure everything is consistent.\n",
    "- **Monday:** Discuss trends and finalize consensus on dataset selection and structure.\n",
    "- **Wednesday:** Complete initial EDA preparation, finalize plan for visualization types.\n",
    "\n",
    "### Week 7\n",
    "- **Monday:** Start building visualizations, assign figure responsibilities to group members.\n",
    "- **Friday:** Review meeting to make sure visualizations are progressing and discuss results and narrative.\n",
    "\n",
    "### Week 8\n",
    "- **Monday:** Compile all visualizations and ensure consistency.\n",
    "- **Wednesday:** Polish everything, ensure code runs cleanly.\n",
    "\n",
    "### Week 9\n",
    "- **Monday:** Final review session, proofread notebook text, verify rubric requirements, and finalize project. Begin preparing video.\n",
    "- **Wednesday:** Submit final project and recording; complete team evaluation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
