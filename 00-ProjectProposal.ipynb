{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Omar Abbasi: Project Administration, Conceptualization, Formal Analysis, Visualization, Writing ‚Äì Original Draft  \n",
    "Zahir Ali: Conceptualization, Visualization, Software, Writing ‚Äì Reviewing/Edits  \n",
    "Adam Hamadene: Research, Formal Analysis  \n",
    "Mostafa Darwish: Visualization, Writing ‚Äì Original Draft, Data Curation  \n",
    "Yasir Rizvi: Data Cleaning \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do funding size, industry sector, and geographic location influence both the likelihood and timing of startup failure versus acquisition?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the world continues to see the intersection of human ingenuity and technological accumulation grow extremely rapidly, this shift in the corporate landscape can be tied back to a specific niche: the prevalence and growth of startups in the post-modern era. As technical knowledge and tools continue to develop, human ingenuity has found itself employed in finding the most useful ways to leverage and expand upon the current era of technology and artificial intelligence. Examples of post-modern startups include Uber, Robinhood, Stripe, Databricks, Canva, and Slack. Ideas for growth and innovation stem from all fields, and are catalyzed from a variety of sources such as corporate America, educational insititutions, and small communities all across the country. However, although the majority of the startups known today are those that found success in climbing the barrier between idea and impact, it is the majority that fall short of overcoming this hurdle and end up failing as a product. In this report, we aim to look at a multitude of variables directly and intrinsically tied to startups and their growth, to determine the coefficient of correlation between various factors such as industry sector, funding, location, and size, and how they impact a startup's ability to come to fruition. Because the growth of startups is relatively new and tied to very modern technological advancements, there is a scarce amount of research done into the causes behind their success and failures. For example, venture capital firms and startup accelerators such as Y Combinator were founded in 2005, making the funding rounds for successful startups a very new principle. Our curiosity lies in looking at the underlying details of the successes and failures for startups in the United States, as it provides an opportunity to discover findings in a modern niche that does not possess the level of academic study that other corporate fields in America do.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Startups with larger funding sizes, operating in high-growth industry sectors, and located within established entrepreneurial ecosystems are less likely to fail and tend to experience longer survival times before either failure or acquisition, whereas startups with smaller funding, in low-growth sectors, or in emerging regions face higher failure risks and shorter time-to-event durations. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "- **Dataset #1**\n",
    "- **Dataset Name**: Startup Success Prediction\n",
    "  - **Link to the dataset**: 'https://www.kaggle.com/datasets/manishkc06/startup-success-prediction/data'\n",
    "  - **Number of observations**: 922 \n",
    "  - **Number of variables**: 49 \n",
    "  - **Most relevant variables for our project**:\n",
    "    - Name/ID: name (entity key used for de-duplication)\n",
    "    - Industry/Sector: labels (needs standardization to top-level sector groups)\n",
    "    - Geography: e.g., city, state_code (normalize to country/region for stratification)\n",
    "    - Funding: e.g., funding_total_usd, first_funding_at, last_funding_at, funding_rounds (USD; heavy-tailed; consider log/winsorization)\n",
    "    - Outcome/Status: status (map to success/failure/censored)\n",
    "    - Timing: founded_at, closed_at (parsed to datetime for time to event metrics)\n",
    "  - **Shortcomings / caveats**:\n",
    "    - Sector taxonomy in labels is noisy; requires collapsing to a consistent hierarchy\n",
    "    - Coverage/selection bias (by region/state/stage) likely; report as limitation and consider cohort/time controls\n",
    "    - Event labeling: status may lag reality; treat \"operating\" as censored in survival framing\n",
    "    - Date gaps: Missing founded_at/closed_at can bias time-to-event; document drop/impute rules\n",
    "\n",
    "\n",
    "- **Dataset #2**\n",
    "  - **Dataset Name**: Big Startup Success/Fail Dataset from Crunchbase\n",
    "  - **Link to the dataset**: `https://www.kaggle.com/datasets/yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase`\n",
    "  - **Number of observations**: Computed in the code cell below (after loading)\n",
    "  - **Number of variables**: Computed in the code cell below (after loading)\n",
    "  - **Most relevant variables for our project**:\n",
    "    - Funding-related: `funding_total_usd` (or similar), `funding_rounds`, `last_funding_at`\n",
    "    - Outcome/status: `status` (e.g., acquired/ipo/operating/closed), `acquired_at`, `closed_at`\n",
    "    - Company profile: `name`, `category`/`industry`, `country`, `region`/`city`, `num_employees`\n",
    "    - Timing: `founded_at` (and event dates as above) for computing time-to-failure or time-to-acquisition\n",
    "  - **Shortcomings / caveats**:\n",
    "    - Potential label noise: outcomes may be simplified; ‚Äúoperating‚Äù does not guarantee long-term success; ‚Äúclosed‚Äù labels may lag reality\n",
    "    - Missing or inconsistent dates across companies, which affects survival/time-to-event analyses\n",
    "    - Possible duplicates or multiple rows for the same company over time; category/industry taxonomy can be messy\n",
    "    - Survivorship and reporting bias inherent to Crunchbase; geographic and sector coverage is uneven\n",
    "\n",
    "If we combine datasets, we will align on common keys (e.g., standardized company names and/or website domains), and normalize geography (country/region) and industry taxonomies before joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: airline-safety.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 ‚Äî Startup Attributes & Sectors (Uploaded File)\n",
    "\n",
    "This dataset contains firm-level records for startups with core attributes that complement the Crunchbase outcomes file: basic identity (e.g., name), sector tags (labels), geography (city, state_code), temporal markers (founded_at, closed_at), funding fields (e.g., funding_total_usd, first_funding_at, last_funding_at, funding_rounds), and current status. After basic de-duplication and cleaning, the file provides 922 unique companies and 49 variables‚Äîan efficient ‚Äúattributes & sectors‚Äù snapshot that pairs naturally with the Crunchbase outcomes table for modeling both likelihood and timing of failure vs. acquisition.\n",
    "\n",
    "Important metrics & units (what they mean):\n",
    "\n",
    "- **Funding totals ('funding_total_usd', USD)**: aggregate capital raised. These values are heavy-tailed (a few very large rounds); use log1p or winsorization in modeling. Medians are typically much lower than means.\n",
    "- **Funding intensity('funding_rounds', count; 'first_funding_at' / 'last_funding_at', dates)**: approximates investor traction and recency of financing activity.\n",
    "- **Timing ('founded_at', 'closed_at', dates)**: used to compute durations like time-to-failure/acquisition in survival or competing-risks framing.\n",
    "- **Geography ('city', 'state_code')**: can be standardized to region/country to analyze spatial effects (ecosystem maturity, capital access).\n",
    "- **Outcome label ('status')**: maps to success (acquired/IPO), failure (closed), or censored (operating/active).\n",
    "\n",
    "Major Concerns with the Dataset:\n",
    "- Self-selection and visibility bias: The dataset mainly includes startups with a public presence or enough significance to have their information recorded online. Smaller or short-lived companies that failed early are likely missing. As a result, the data overrepresents well-funded or high-profile firms, creating a visibility bias that favors more successful ventures and underrepresents smaller or less visible startups.\n",
    "- Geographic and sector imbalance: The dataset is heavily concentrated in major tech hubs like San Francisco, New York, and London, while smaller or emerging regions are underrepresented. It also overrepresents technology-focused industries such as software, e-commerce, and fintech, limiting how broadly the results can be applied to other sectors.\n",
    "- Survivorship bias and reporting lag: Active or successful startups are more likely to update their data, while failed or older companies are underrepresented, creating survivorship bias. Reporting delays for closures or acquisitions may also cause the dataset to miss recent outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded dataset from: data/00-raw/startup_data.csv\n",
      "Shape (rows, columns): (923, 49)\n",
      "The dataset contains 923 rows and 49 columns.\n",
      "\n",
      "üîç Missingness (% of missing values per column):\n",
      "closed_at                   63.7\n",
      "unnamed:_6                  53.4\n",
      "age_last_milestone_year     16.5\n",
      "age_first_milestone_year    16.5\n",
      "state_code_1                 0.1\n",
      "unnamed:_0                   0.0\n",
      "is_biotech                   0.0\n",
      "is_software                  0.0\n",
      "is_web                       0.0\n",
      "is_mobile                    0.0\n",
      "dtype: float64\n",
      "\n",
      "Top correlated missingness (possible systematic gaps):\n",
      "unnamed:_6                unnamed:_6      1.000000\n",
      "                          closed_at       0.139718\n",
      "                          state_code_1    0.030757\n",
      "age_first_milestone_year  state_code_1   -0.014623\n",
      "closed_at                 state_code_1   -0.043632\n",
      "age_first_milestone_year  unnamed:_6     -0.118216\n",
      "                          closed_at      -0.302727\n",
      "unnamed:_0                unnamed:_0           NaN\n",
      "dtype: float64\n",
      "\n",
      "üí∞ Outlier detection for funding_total_usd:\n",
      "IQR bounds = [-30,275,000, 57,725,000]\n",
      "Outliers flagged: 65 rows\n",
      "\n",
      "üßπ Cleaned dataset: 923 -> 923 rows after cleaning.\n",
      "\n",
      "üìä Summary statistics for key variables:\n",
      "                   count unique            top freq             mean  \\\n",
      "funding_total_usd  923.0    NaN            NaN  NaN  25419749.092091   \n",
      "funding_rounds     923.0    NaN            NaN  NaN         2.310943   \n",
      "status               923      2       acquired  597              NaN   \n",
      "city                 923    221  San Francisco  128              NaN   \n",
      "state_code           923     35             CA  488              NaN   \n",
      "\n",
      "                                std      min        25%         50%  \\\n",
      "funding_total_usd  189634364.488794  11000.0  2725000.0  10000000.0   \n",
      "funding_rounds             1.390922      1.0        1.0         2.0   \n",
      "status                          NaN      NaN        NaN         NaN   \n",
      "city                            NaN      NaN        NaN         NaN   \n",
      "state_code                      NaN      NaN        NaN         NaN   \n",
      "\n",
      "                          75%           max  \n",
      "funding_total_usd  24725000.0  5700000000.0  \n",
      "funding_rounds            3.0          10.0  \n",
      "status                    NaN           NaN  \n",
      "city                      NaN           NaN  \n",
      "state_code                NaN           NaN  \n",
      "\n",
      "‚úÖ Cleaned dataset saved to: data/02-processed/dataset1_startup_data_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Dataset #1 ‚Äî Load, Tidy, Profile, and Clean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "INTERIM_DIR = Path(\"data/01-interim\")\n",
    "PROCESSED_DIR = Path(\"data/02-processed\")\n",
    "for d in [RAW_DIR, INTERIM_DIR, PROCESSED_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "raw_path = RAW_DIR / \"startup_data.csv\"  \n",
    "df = pd.read_csv(raw_path)\n",
    "print(f\"‚úÖ Loaded dataset from: {raw_path}\")\n",
    "\n",
    "\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\"-\", \"_\")\n",
    "    .str.replace(\"/\", \"_\")\n",
    "    .str.replace(\".\", \"_\")\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Shape (rows, columns): {df.shape}\")\n",
    "\n",
    "\n",
    "print(f\"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "\n",
    "missing_pct = (df.isna().mean() * 100).round(1).sort_values(ascending=False)\n",
    "print(\"\\nüîç Missingness (% of missing values per column):\")\n",
    "print(missing_pct.head(10))\n",
    "\n",
    "\n",
    "nan_corr = df.isna().corr()\n",
    "if nan_corr.shape[0] > 1:\n",
    "    print(\"\\nTop correlated missingness (possible systematic gaps):\")\n",
    "    corr_pairs = (\n",
    "        nan_corr.unstack()\n",
    "        .sort_values(ascending=False)\n",
    "        .drop_duplicates()\n",
    "        .head(10)\n",
    "    )\n",
    "    print(corr_pairs)\n",
    "\n",
    "if \"funding_total_usd\" in df.columns:\n",
    "    series = pd.to_numeric(df[\"funding_total_usd\"], errors=\"coerce\").dropna()\n",
    "    if len(series) > 0:\n",
    "        q1, q3 = np.percentile(series, [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "        df[\"funding_outlier_flag\"] = (\n",
    "            (df[\"funding_total_usd\"] < lower) | (df[\"funding_total_usd\"] > upper)\n",
    "        )\n",
    "        print(\n",
    "            f\"\\nüí∞ Outlier detection for funding_total_usd:\\n\"\n",
    "            f\"IQR bounds = [{lower:,.0f}, {upper:,.0f}]\\n\"\n",
    "            f\"Outliers flagged: {df['funding_outlier_flag'].sum()} rows\"\n",
    "        )\n",
    "    else:\n",
    "        df[\"funding_outlier_flag\"] = False\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No 'funding_total_usd' column found for outlier analysis.\")\n",
    "    df[\"funding_outlier_flag\"] = False\n",
    "\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "if {\"name\", \"status\"}.issubset(df.columns):\n",
    "    df = df.dropna(subset=[\"name\", \"status\"], how=\"all\")\n",
    "print(f\"\\nüßπ Cleaned dataset: {before} -> {len(df)} rows after cleaning.\")\n",
    "\n",
    "important_vars = [c for c in [\"funding_total_usd\", \"funding_rounds\", \"status\", \"city\", \"state_code\"] if c in df.columns]\n",
    "print(\"\\nüìä Summary statistics for key variables:\")\n",
    "print(df[important_vars].describe(include=\"all\").transpose().iloc[:10])\n",
    "\n",
    "processed_path = PROCESSED_DIR / \"dataset1_startup_data_processed.csv\"\n",
    "df.to_csv(processed_path, index=False)\n",
    "print(f\"\\n‚úÖ Cleaned dataset saved to: {processed_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 ‚Äî Crunchbase Startup Outcomes (Failure vs. Acquisition)\n",
    "\n",
    "This dataset contains company-level records from Crunchbase with profile attributes (name, industry/category), geography (country, region/city), funding history (total USD raised, number of rounds, last funding date), and outcome indicators (operating, acquired, IPO, closed) with event timestamps. It directly supports our hypothesis by enabling both:\n",
    "\n",
    "- Likelihood modeling: whether a startup ultimately fails (closed) or is successfully exited (acquired/IPO).\n",
    "- Timing modeling: how long it takes from founding to failure vs. acquisition (time-to-event).\n",
    "\n",
    "Scope and variables aligned to the hypothesis:\n",
    "- **Funding size and intensity**: `funding_total_usd` (USD, heavy‚Äëtailed), `funding_rounds` (count), `last_funding_at` (recency control).\n",
    "- **Industry sector**: `category`/`industry`/`category_list` (will standardize to a consistent taxonomy and allow multi-label handling when needed).\n",
    "- **Geographic location**: `country`/`country_code`, `region`/`city` (we will normalize to country and, when available, region for stratification).\n",
    "- **Outcomes and timing**: `status` plus event dates `acquired_at`, `closed_at`, and baseline `founded_at` to compute durations.\n",
    "\n",
    "Outcome coding and analysis framing:\n",
    "- **Success**: acquired or IPO.\n",
    "- **Failure**: closed.\n",
    "- **Censored**: operating/active at last observation (no terminal event yet).\n",
    "- We will treat timing via survival/competing‚Äërisks framing: time from `founded_at` to first terminal event (acquisition or closure), censoring otherwise. This supports estimating how funding, sector, and geography shift both hazards and ultimate probabilities.\n",
    "\n",
    "Key data characteristics and handling notes:\n",
    "- **Heavy tails in funding**: consider log1p transform or winsorization; flag extreme outliers for sensitivity checks.\n",
    "- **Sector taxonomy**: categories are noisy/inconsistent; we will collapse to a manageable hierarchy (e.g., top‚Äëlevel sector groups).\n",
    "- **Geographic normalization**: standardize country codes; map regions/cities to country, and use region only when coverage is sufficient.\n",
    "- **Missingness**: dates and categories can be absent; we will profile missingness, document imputation/dropping rules, and avoid introducing informative censoring.\n",
    "- **Entity resolution**: de‚Äëduplicate by exact rows and harmonized `name`; spot‚Äëcheck ambiguous entities.\n",
    "- **Coverage bias**: Crunchbase coverage varies by sector, geography, and stage; we will include cohort/time fixed effects where needed and report limitations.\n",
    "\n",
    "Wrangling plan(TBD, can be altered...):\n",
    "- Load from `data/00-raw/`, standardize column names and types, parse dates, harmonize sector and geography, derive `outcome_label` and `time_to_event_days`, flag funding outliers, and export an analysis‚Äëready file to `data/02-processed/` for modeling likelihood and timing of failure vs. acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Override file not found: data/00-raw/dataset2.csv. Place it in data/00-raw or update RAW_FILENAME_OVERRIDE.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     70\u001b[39m     ranked = \u001b[38;5;28msorted\u001b[39m(csvs, key=score, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ranked[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m raw_path = \u001b[43mpick_raw_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRAW_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRAW_FILENAME_OVERRIDE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSelected raw file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Use low_memory=False for mixed types, and keep original column names for inspection before standardization\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mpick_raw_file\u001b[39m\u001b[34m(raw_dir, override)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m candidate.exists():\n\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m candidate\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m     54\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOverride file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcandidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Place it in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or update RAW_FILENAME_OVERRIDE.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m     )\n\u001b[32m     57\u001b[39m csvs = \u001b[38;5;28msorted\u001b[39m(raw_dir.glob(\u001b[33m\"\u001b[39m\u001b[33m*.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m csvs:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Override file not found: data/00-raw/dataset2.csv. Place it in data/00-raw or update RAW_FILENAME_OVERRIDE."
     ]
    }
   ],
   "source": [
    "# Crunchbase Startup Success/Fail ‚Äî Load, Clean, Tidy, Wrangle\n",
    "#\n",
    "# Notes:\n",
    "# - Place the Kaggle CSV from the dataset into `data/00-raw/`.\n",
    "# - If multiple CSVs exist, this cell attempts to auto-detect the most likely file.\n",
    "# - Adjust `RAW_FILENAME_OVERRIDE` if auto-detection fails.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "INTERIM_DIR = Path(\"data/01-interim\")\n",
    "PROCESSED_DIR = Path(\"data/02-processed\")\n",
    "\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you know the exact filename, set it here; otherwise keep as None\n",
    "RAW_FILENAME_OVERRIDE: Optional[str] = \"dataset2.csv\"  # renamed for consistency\n",
    "\n",
    "# Heuristics for picking likely files\n",
    "LIKELY_SUBSTRINGS: List[str] = [\n",
    "    \"crunchbase\",\n",
    "    \"startup\",\n",
    "    \"startups\",\n",
    "    \"success\",\n",
    "    \"fail\",\n",
    "]\n",
    "\n",
    "\n",
    "def pick_raw_file(raw_dir: Path, override: Optional[str]) -> Path:\n",
    "    \"\"\"Pick the most likely raw CSV file for the Crunchbase dataset.\n",
    "\n",
    "    Args:\n",
    "        raw_dir: Directory containing raw files.\n",
    "        override: Explicit filename if known.\n",
    "\n",
    "    Returns:\n",
    "        Path to the selected CSV file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no suitable file is found.\n",
    "    \"\"\"\n",
    "    if override is not None:\n",
    "        candidate = raw_dir / override\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        raise FileNotFoundError(\n",
    "            f\"Override file not found: {candidate}. Place it in {raw_dir} or update RAW_FILENAME_OVERRIDE.\"\n",
    "        )\n",
    "\n",
    "    csvs = sorted(raw_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No CSV files found in {raw_dir}. Download the Kaggle dataset and place the CSV here.\"\n",
    "        )\n",
    "\n",
    "    # Rank by substring match then by size (descending)\n",
    "    def score(p: Path) -> tuple[int, int]:\n",
    "        name = p.name.lower()\n",
    "        match_score = sum(1 for s in LIKELY_SUBSTRINGS if s in name)\n",
    "        size_score = p.stat().st_size\n",
    "        return (match_score, size_score)\n",
    "\n",
    "    ranked = sorted(csvs, key=score, reverse=True)\n",
    "    return ranked[0]\n",
    "\n",
    "\n",
    "raw_path = pick_raw_file(RAW_DIR, RAW_FILENAME_OVERRIDE)\n",
    "print(f\"Selected raw file: {raw_path}\")\n",
    "\n",
    "# Load data\n",
    "# Use low_memory=False for mixed types, and keep original column names for inspection before standardization\n",
    "raw_df = pd.read_csv(raw_path, low_memory=False)\n",
    "print(f\"Raw shape: {raw_df.shape}\")\n",
    "\n",
    "# Standardize column names: snake_case\n",
    "raw_df.columns = (\n",
    "    raw_df.columns.str.strip().str.replace(\" \", \"_\", regex=False).str.replace(\"-\", \"_\", regex=False).str.lower()\n",
    ")\n",
    "\n",
    "# Basic de-duplication by exact row match and by name if present\n",
    "if \"name\" in raw_df.columns:\n",
    "    before = len(raw_df)\n",
    "    raw_df = raw_df.drop_duplicates()\n",
    "    raw_df = raw_df.drop_duplicates(subset=[\"name\"], keep=\"first\")\n",
    "    print(f\"Dropped duplicates -> {before} -> {len(raw_df)} rows\")\n",
    "else:\n",
    "    raw_df = raw_df.drop_duplicates()\n",
    "\n",
    "# Identify key columns by fuzzy names\n",
    "def find_col(candidates: List[str]) -> Optional[str]:\n",
    "    cols = set(raw_df.columns)\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "col_name = find_col([\"name\", \"company\", \"company_name\"])\n",
    "col_status = find_col([\"status\", \"state\", \"current_status\"])  # typical outcome label\n",
    "col_funded_total = find_col([\"funding_total_usd\", \"funding_total\", \"total_funding_usd\", \"total_funding\"])\n",
    "col_rounds = find_col([\"funding_rounds\", \"num_funding_rounds\", \"rounds\"])\n",
    "col_category = find_col([\"category\", \"category_list\", \"industry\", \"category_groups\"])\n",
    "col_country = find_col([\"country\", \"country_code\", \"country_iso\", \"country_name\"])\n",
    "col_region = find_col([\"region\", \"state_region\", \"state\", \"city\", \"location\"])\n",
    "col_founded = find_col([\"founded_at\", \"founded\", \"founded_date\"])  # date-like\n",
    "col_acquired = find_col([\"acquired_at\", \"acquired\", \"acquisition_date\"])  # date-like\n",
    "col_closed = find_col([\"closed_at\", \"closed\", \"closing_date\"])  # date-like\n",
    "col_last_funding = find_col([\"last_funding_at\", \"last_funding_date\"])  # date-like\n",
    "col_employees = find_col([\"num_employees\", \"employee_count\", \"employees\"])\n",
    "\n",
    "# Restrict to relevant columns (retain existing only)\n",
    "keep_cols: List[str] = [\n",
    "    c\n",
    "    for c in [\n",
    "        col_name,\n",
    "        col_status,\n",
    "        col_funded_total,\n",
    "        col_rounds,\n",
    "        col_category,\n",
    "        col_country,\n",
    "        col_region,\n",
    "        col_founded,\n",
    "        col_acquired,\n",
    "        col_closed,\n",
    "        col_last_funding,\n",
    "        col_employees,\n",
    "    ]\n",
    "    if c is not None\n",
    "]\n",
    "\n",
    "work_df = raw_df[keep_cols].copy()\n",
    "print(f\"Working shape (selected columns): {work_df.shape}\")\n",
    "\n",
    "# Parse dates where present\n",
    "for dcol in [col_founded, col_acquired, col_closed, col_last_funding]:\n",
    "    if dcol is not None and dcol in work_df.columns:\n",
    "        work_df[dcol] = pd.to_datetime(work_df[dcol], errors=\"coerce\")\n",
    "\n",
    "# Coerce funding to numeric USD if present\n",
    "if col_funded_total is not None and col_funded_total in work_df.columns:\n",
    "    # Remove currency symbols/commas if any\n",
    "    work_df[col_funded_total] = (\n",
    "        work_df[col_funded_total]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\", regex=False)\n",
    "        .str.replace(\"$\", \"\", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    work_df[col_funded_total] = pd.to_numeric(work_df[col_funded_total], errors=\"coerce\")\n",
    "\n",
    "# Derive outcome label: success/failure/censored\n",
    "# success: acquired or IPO; failure: closed; censored: operating/others with no terminal date\n",
    "def derive_outcome(status_val: Optional[str]) -> Optional[str]:\n",
    "    if status_val is None or pd.isna(status_val):\n",
    "        return None\n",
    "    s = str(status_val).strip().lower()\n",
    "    if any(tok in s for tok in [\"acquired\", \"ipo\"]):\n",
    "        return \"success\"\n",
    "    if \"closed\" in s:\n",
    "        return \"failure\"\n",
    "    if any(tok in s for tok in [\"operating\", \"active\"]):\n",
    "        return \"censored\"\n",
    "    return None\n",
    "\n",
    "if col_status is not None and col_status in work_df.columns:\n",
    "    work_df[\"outcome_label\"] = work_df[col_status].map(derive_outcome)\n",
    "else:\n",
    "    work_df[\"outcome_label\"] = None\n",
    "\n",
    "# Time-to-event from founded to first terminal event if present\n",
    "def pick_event_date(row: pd.Series) -> pd.Timestamp | pd.NaT:\n",
    "    # prefer acquired/closed dates; else NaT\n",
    "    acquired_date = row[col_acquired] if col_acquired in row and pd.notna(row[col_acquired]) else pd.NaT\n",
    "    closed_date = row[col_closed] if col_closed in row and pd.notna(row[col_closed]) else pd.NaT\n",
    "    # pick whichever is earliest non-NaT\n",
    "    if pd.notna(acquired_date) and pd.notna(closed_date):\n",
    "        return min(acquired_date, closed_date)\n",
    "    if pd.notna(acquired_date):\n",
    "        return acquired_date\n",
    "    if pd.notna(closed_date):\n",
    "        return closed_date\n",
    "    return pd.NaT\n",
    "\n",
    "if col_founded is not None and col_founded in work_df.columns:\n",
    "    work_df[\"event_date\"] = work_df.apply(pick_event_date, axis=1)\n",
    "    work_df[\"time_to_event_days\"] = (\n",
    "        work_df[\"event_date\"] - work_df[col_founded]\n",
    "    ).dt.days\n",
    "else:\n",
    "    work_df[\"event_date\"] = pd.NaT\n",
    "    work_df[\"time_to_event_days\"] = np.nan\n",
    "\n",
    "# Missingness profile\n",
    "missing_pct = work_df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nMissingness (% of rows missing per column):\")\n",
    "print((missing_pct * 100).round(1))\n",
    "\n",
    "# Flag outliers in funding (IQR method)\n",
    "if col_funded_total is not None and col_funded_total in work_df.columns:\n",
    "    fund = work_df[col_funded_total].dropna()\n",
    "    if len(fund) > 0:\n",
    "        q1, q3 = np.percentile(fund, [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        lower = max(0, q1 - 1.5 * iqr)\n",
    "        work_df[\"funding_outlier_flag\"] = (\n",
    "            (work_df[col_funded_total] < lower) | (work_df[col_funded_total] > upper)\n",
    "        )\n",
    "        print(\n",
    "            f\"Funding IQR bounds -> lower={lower:,.0f}, upper={upper:,.0f}; \"\n",
    "            f\"outliers flagged: {work_df['funding_outlier_flag'].sum()}\"\n",
    "        )\n",
    "    else:\n",
    "        work_df[\"funding_outlier_flag\"] = False\n",
    "else:\n",
    "    work_df[\"funding_outlier_flag\"] = False\n",
    "\n",
    "# Minimal cleaning: drop rows with no name and no status\n",
    "min_keep_cols = [c for c in [col_name, col_status] if c is not None]\n",
    "if min_keep_cols:\n",
    "    before = len(work_df)\n",
    "    work_df = work_df.dropna(subset=min_keep_cols, how=\"all\")\n",
    "    print(f\"Dropped rows missing all of {min_keep_cols}: {before} -> {len(work_df)}\")\n",
    "\n",
    "# Save processed\n",
    "processed_path = PROCESSED_DIR / \"startups_crunchbase_processed.csv\"\n",
    "work_df.to_csv(processed_path, index=False)\n",
    "print(f\"\\nProcessed file written to: {processed_path}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nSummary:\")\n",
    "print({\n",
    "    \"n_rows\": len(work_df),\n",
    "    \"n_cols\": work_df.shape[1],\n",
    "    \"outcome_counts\": work_df[\"outcome_label\"].value_counts(dropna=False).to_dict() if \"outcome_label\" in work_df else {},\n",
    "})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
"source": [
"- **Bias & fairness:** Datasets may favor startups or sectors that are much higher in popularity and show a bias towards well known startups. There are also concerns with issues of generlzation as some areas may have high density of startups compared to others potential misrepresenting the data.\n",
"- **Generalization limits:** As mentioned previously, Kaggle datasets in particular may overrepresent high success startups due to the ease of accessing the data. This results in the data not geenrlazaing to non-tech or smaller companies. We intend to avoid general claims and make specifc statements that are contextualized by environment maturity.\n",
"- **Data sensitivity:** Although the data gathered is public, names and emails can be used to reidenifty an individual, or any specific data points that can be used to triangulate a person or startup.¬†\n",
"- **Non-Consensual Use of Company Information:** Despite the data being public, startups in the dataset did not consent to be analyzed or used for prediction exercises. We will be using aggregated analysis and not single out any companies.\n",
"- **Potential Misrepresentation Due to Inaccurate or Incomplete Data:** Startup databases are often incomplete, outdated, or wrong because the data is crowdsourced. We will treat the data as approximate and emphasize uncertainty rather than presenting results as definitive truth.\n",
"- **Responsibility to Prevent Harmful Use of Results:** If someone misuses the findings it may influence funding or hiring decisions, or perceptions of certain industries/regions. We will explicitly state that the work should not be used for investment decisions.\n"
]


   
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regard to communication, we plan on using iMessage to text one another. We believe this is one of the most efficient and easiest ways for us to contact one another. As for the  messaging itself, all members have agreed to expect a response, whether that be a message or a reaction, from each group member within 3 hours of the initial text being sent. We will meet twice per week, every Monday morning, we will reserve a study space in the Geisel Library to meet and provide updates, followed by a Zoom meeting every Friday afternoon to consolidate the designated progress from Monday's meeting. In regard to tone, we agree to all expect respectful interactions. Even when a disagreement takes place, the person expressing a lack of approval should explain their reasoning, as well as an alternative method that they believe is better. We will be concise and to the point, but still maintain respect for one another and everyone's ideas. We plan to use voting to make decisions as a group, especially for disagreements and changes to our original plan. The project administrator will be in charge of calling the vote, and we will go with the majority ruling, as we have 5 people. We will not accept abstaining from votes. We have specialized roles for each person; however, because there is overlap, we do plan to share many of the responsibilities. As we are a team, we plan on helping each other out when possible, especially if one person is struggling with a specific task. We assign roles and tasks based on the skillsets of the members, which we have already discussed in detail. We have set a policy that struggles are inevitable, as we are all busy. We have a guideline that whenever someone is falling behind, there is no hassle or problem in expressing that as early as possible. We would rather know what to fix earlier in the process, rather than have a last-minute lack of execution. Struggles with certain tasks should be expressed immediately, as we will set egos aside to help regardless of role/assigned tasks, in order to prioritize the team as a unit/whole.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
  "source": [
  "Monday, Week 3: Meeting to go over each member's final proposal for the idea they would like to put forward\n",
  "Friday, Week 3: Zoom meeting to vote on the final project idea decision.\n",
  "Sunday, Week 3: Zoom meeting to discuss roles and consolidate datasets that each member has found\n",
  "Monday, Week 4: Meeting in Geisel Library to consolidate datasets, and to assign roles for the project proposal. Begin working on data cleaning and transformations, and design plans for visualizations.\n",
  "Wednesday, Week 4: Proofread entire proposal, tighten up wording and presentation.\n"
]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COGS108_FA25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
