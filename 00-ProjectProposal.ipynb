{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Omar Abbasi: Project Administration, Conceptualization, Formal Analysis, Visualization, Writing – Original Draft  \n",
    "Zahir Ali: Conceptualization, Visualization, Software, Writing – Reviewing/Edits  \n",
    "Adam Hamadene: Research, Formal Analysis  \n",
    "Mostafa Darwish: Visualization, Writing – Original Draft, Data Curation  \n",
    "Yasir Rizvi: Data Cleaning \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do funding size, industry sector, and geographic location influence both the likelihood and timing of startup failure versus acquisition?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "- **Dataset #1**: See section below for details, loading, and wrangling steps.\n",
    "\n",
    "- **Dataset #2**\n",
    "  - **Dataset Name**: Big Startup Success/Fail Dataset from Crunchbase\n",
    "  - **Link to the dataset**: `https://www.kaggle.com/datasets/yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase`\n",
    "  - **Number of observations**: Computed in the code cell below (after loading)\n",
    "  - **Number of variables**: Computed in the code cell below (after loading)\n",
    "  - **Most relevant variables for our project**:\n",
    "    - Funding-related: `funding_total_usd` (or similar), `funding_rounds`, `last_funding_at`\n",
    "    - Outcome/status: `status` (e.g., acquired/ipo/operating/closed), `acquired_at`, `closed_at`\n",
    "    - Company profile: `name`, `category`/`industry`, `country`, `region`/`city`, `num_employees`\n",
    "    - Timing: `founded_at` (and event dates as above) for computing time-to-failure or time-to-acquisition\n",
    "  - **Shortcomings / caveats**:\n",
    "    - Potential label noise: outcomes may be simplified; “operating” does not guarantee long-term success; “closed” labels may lag reality\n",
    "    - Missing or inconsistent dates across companies, which affects survival/time-to-event analyses\n",
    "    - Possible duplicates or multiple rows for the same company over time; category/industry taxonomy can be messy\n",
    "    - Survivorship and reporting bias inherent to Crunchbase; geographic and sector coverage is uneven\n",
    "\n",
    "If we combine datasets, we will align on common keys (e.g., standardized company names and/or website domains), and normalize geography (country/region) and industry taxonomies before joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startup Success/Fail Dataset from Crunchbase\n",
    "\n",
    "This dataset aggregates company-level records from Crunchbase, including basic profile fields (name, industry/category, geography), funding history (e.g., number of rounds, last funding date, total funding), and outcome indicators (e.g., operating, acquired, IPO, closed). These variables are directly relevant to our research question because they allow us to:\n",
    "\n",
    "- Quantify funding size and intensity via `funding_total_usd` and `funding_rounds`.\n",
    "- Identify industry sector using category taxonomy fields.\n",
    "- Place companies geographically using country and region/city fields.\n",
    "- Measure both the likelihood and timing of outcomes using `status` along with event dates such as `acquired_at` and `closed_at`.\n",
    "\n",
    "Key metrics and units, with interpretation:\n",
    "- **Funding totals (USD)**: Continuous financial magnitude; heavy-tailed and requires robust treatment (log transform or winsorization).\n",
    "- **Funding rounds (count)**: Discrete intensity of investor validation; potentially confounded by time and sector norms.\n",
    "- **Status / outcome (categorical)**: Typical labels include operating, acquired, IPO, closed. For analysis, we will map to success (acquired or IPO) and failure (closed). Operating can be treated as right-censored in time-to-event analyses.\n",
    "- **Dates (ISO-like strings)**: `founded_at`, `last_funding_at`, `acquired_at`, `closed_at`. We will parse to datetime and compute durations, e.g., time from founding to acquisition/closure.\n",
    "\n",
    "Major concerns and data limitations:\n",
    "- **Labeling and censoring**: “Operating” is not the same as success; many operating companies will eventually fail or be acquired. We will treat these as censored when modeling time-to-event.\n",
    "- **Missingness / inconsistency**: Dates, industries, and geographies are often missing or non-standard. We will profile missingness and document any imputation or row-dropping.\n",
    "- **Duplicates / entity resolution**: Company names can collide; we will check for likely duplicates and standardize names to reduce double counting.\n",
    "- **Bias**: Crunchbase coverage is uneven by geography and sector, and reporting incentives differ by outcome and company size.\n",
    "\n",
    "We will follow the same wrangling standards as Dataset #1: load from `data/00-raw/`, tidy column names, validate types, inspect missingness systematically, flag outliers in funding, derive outcome labels and time-to-event targets, and save a clean, analysis-ready CSV to `data/02-processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected raw file: data/00-raw/big_startup_secsees_dataset.csv\n",
      "Raw shape: (66368, 14)\n",
      "Dropped duplicates -> 66368 -> 66103 rows\n",
      "Working shape (selected columns): (66103, 9)\n",
      "\n",
      "Missingness (% of rows missing per column):\n",
      "event_date            100.0\n",
      "time_to_event_days    100.0\n",
      "founded_at             22.9\n",
      "funding_total_usd      19.2\n",
      "region                 12.1\n",
      "country_code           10.5\n",
      "category_list           4.7\n",
      "name                    0.0\n",
      "status                  0.0\n",
      "funding_rounds          0.0\n",
      "last_funding_at         0.0\n",
      "outcome_label           0.0\n",
      "dtype: float64\n",
      "Funding IQR bounds -> lower=0, upper=24,495,250; outliers flagged: 7363\n",
      "Dropped rows missing all of ['name', 'status']: 66103 -> 66103\n",
      "\n",
      "Processed file written to: data/02-processed/startups_crunchbase_processed.csv\n",
      "\n",
      "Summary:\n",
      "{'n_rows': 66103, 'n_cols': 13, 'outcome_counts': {'censored': 52812, 'success': 7088, 'failure': 6203}}\n"
     ]
    }
   ],
   "source": [
    "# Crunchbase Startup Success/Fail — Load, Clean, Tidy, Wrangle\n",
    "#\n",
    "# Notes:\n",
    "# - Place the Kaggle CSV from the dataset into `data/00-raw/`.\n",
    "# - If multiple CSVs exist, this cell attempts to auto-detect the most likely file.\n",
    "# - Adjust `RAW_FILENAME_OVERRIDE` if auto-detection fails.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "INTERIM_DIR = Path(\"data/01-interim\")\n",
    "PROCESSED_DIR = Path(\"data/02-processed\")\n",
    "\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you know the exact filename, set it here; otherwise keep as None\n",
    "RAW_FILENAME_OVERRIDE: Optional[str] = \"dataset2.csv\"  # renamed for consistency\n",
    "\n",
    "# Heuristics for picking likely files\n",
    "LIKELY_SUBSTRINGS: List[str] = [\n",
    "    \"crunchbase\",\n",
    "    \"startup\",\n",
    "    \"startups\",\n",
    "    \"success\",\n",
    "    \"fail\",\n",
    "]\n",
    "\n",
    "\n",
    "def pick_raw_file(raw_dir: Path, override: Optional[str]) -> Path:\n",
    "    \"\"\"Pick the most likely raw CSV file for the Crunchbase dataset.\n",
    "\n",
    "    Args:\n",
    "        raw_dir: Directory containing raw files.\n",
    "        override: Explicit filename if known.\n",
    "\n",
    "    Returns:\n",
    "        Path to the selected CSV file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no suitable file is found.\n",
    "    \"\"\"\n",
    "    if override is not None:\n",
    "        candidate = raw_dir / override\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        raise FileNotFoundError(\n",
    "            f\"Override file not found: {candidate}. Place it in {raw_dir} or update RAW_FILENAME_OVERRIDE.\"\n",
    "        )\n",
    "\n",
    "    csvs = sorted(raw_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No CSV files found in {raw_dir}. Download the Kaggle dataset and place the CSV here.\"\n",
    "        )\n",
    "\n",
    "    # Rank by substring match then by size (descending)\n",
    "    def score(p: Path) -> tuple[int, int]:\n",
    "        name = p.name.lower()\n",
    "        match_score = sum(1 for s in LIKELY_SUBSTRINGS if s in name)\n",
    "        size_score = p.stat().st_size\n",
    "        return (match_score, size_score)\n",
    "\n",
    "    ranked = sorted(csvs, key=score, reverse=True)\n",
    "    return ranked[0]\n",
    "\n",
    "\n",
    "raw_path = pick_raw_file(RAW_DIR, RAW_FILENAME_OVERRIDE)\n",
    "print(f\"Selected raw file: {raw_path}\")\n",
    "\n",
    "# Load data\n",
    "# Use low_memory=False for mixed types, and keep original column names for inspection before standardization\n",
    "raw_df = pd.read_csv(raw_path, low_memory=False)\n",
    "print(f\"Raw shape: {raw_df.shape}\")\n",
    "\n",
    "# Standardize column names: snake_case\n",
    "raw_df.columns = (\n",
    "    raw_df.columns.str.strip().str.replace(\" \", \"_\", regex=False).str.replace(\"-\", \"_\", regex=False).str.lower()\n",
    ")\n",
    "\n",
    "# Basic de-duplication by exact row match and by name if present\n",
    "if \"name\" in raw_df.columns:\n",
    "    before = len(raw_df)\n",
    "    raw_df = raw_df.drop_duplicates()\n",
    "    raw_df = raw_df.drop_duplicates(subset=[\"name\"], keep=\"first\")\n",
    "    print(f\"Dropped duplicates -> {before} -> {len(raw_df)} rows\")\n",
    "else:\n",
    "    raw_df = raw_df.drop_duplicates()\n",
    "\n",
    "# Identify key columns by fuzzy names\n",
    "def find_col(candidates: List[str]) -> Optional[str]:\n",
    "    cols = set(raw_df.columns)\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "col_name = find_col([\"name\", \"company\", \"company_name\"])\n",
    "col_status = find_col([\"status\", \"state\", \"current_status\"])  # typical outcome label\n",
    "col_funded_total = find_col([\"funding_total_usd\", \"funding_total\", \"total_funding_usd\", \"total_funding\"])\n",
    "col_rounds = find_col([\"funding_rounds\", \"num_funding_rounds\", \"rounds\"])\n",
    "col_category = find_col([\"category\", \"category_list\", \"industry\", \"category_groups\"])\n",
    "col_country = find_col([\"country\", \"country_code\", \"country_iso\", \"country_name\"])\n",
    "col_region = find_col([\"region\", \"state_region\", \"state\", \"city\", \"location\"])\n",
    "col_founded = find_col([\"founded_at\", \"founded\", \"founded_date\"])  # date-like\n",
    "col_acquired = find_col([\"acquired_at\", \"acquired\", \"acquisition_date\"])  # date-like\n",
    "col_closed = find_col([\"closed_at\", \"closed\", \"closing_date\"])  # date-like\n",
    "col_last_funding = find_col([\"last_funding_at\", \"last_funding_date\"])  # date-like\n",
    "col_employees = find_col([\"num_employees\", \"employee_count\", \"employees\"])\n",
    "\n",
    "# Restrict to relevant columns (retain existing only)\n",
    "keep_cols: List[str] = [\n",
    "    c\n",
    "    for c in [\n",
    "        col_name,\n",
    "        col_status,\n",
    "        col_funded_total,\n",
    "        col_rounds,\n",
    "        col_category,\n",
    "        col_country,\n",
    "        col_region,\n",
    "        col_founded,\n",
    "        col_acquired,\n",
    "        col_closed,\n",
    "        col_last_funding,\n",
    "        col_employees,\n",
    "    ]\n",
    "    if c is not None\n",
    "]\n",
    "\n",
    "work_df = raw_df[keep_cols].copy()\n",
    "print(f\"Working shape (selected columns): {work_df.shape}\")\n",
    "\n",
    "# Parse dates where present\n",
    "for dcol in [col_founded, col_acquired, col_closed, col_last_funding]:\n",
    "    if dcol is not None and dcol in work_df.columns:\n",
    "        work_df[dcol] = pd.to_datetime(work_df[dcol], errors=\"coerce\")\n",
    "\n",
    "# Coerce funding to numeric USD if present\n",
    "if col_funded_total is not None and col_funded_total in work_df.columns:\n",
    "    # Remove currency symbols/commas if any\n",
    "    work_df[col_funded_total] = (\n",
    "        work_df[col_funded_total]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\", regex=False)\n",
    "        .str.replace(\"$\", \"\", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    work_df[col_funded_total] = pd.to_numeric(work_df[col_funded_total], errors=\"coerce\")\n",
    "\n",
    "# Derive outcome label: success/failure/censored\n",
    "# success: acquired or IPO; failure: closed; censored: operating/others with no terminal date\n",
    "def derive_outcome(status_val: Optional[str]) -> Optional[str]:\n",
    "    if status_val is None or pd.isna(status_val):\n",
    "        return None\n",
    "    s = str(status_val).strip().lower()\n",
    "    if any(tok in s for tok in [\"acquired\", \"ipo\"]):\n",
    "        return \"success\"\n",
    "    if \"closed\" in s:\n",
    "        return \"failure\"\n",
    "    if any(tok in s for tok in [\"operating\", \"active\"]):\n",
    "        return \"censored\"\n",
    "    return None\n",
    "\n",
    "if col_status is not None and col_status in work_df.columns:\n",
    "    work_df[\"outcome_label\"] = work_df[col_status].map(derive_outcome)\n",
    "else:\n",
    "    work_df[\"outcome_label\"] = None\n",
    "\n",
    "# Time-to-event from founded to first terminal event if present\n",
    "def pick_event_date(row: pd.Series) -> pd.Timestamp | pd.NaT:\n",
    "    # prefer acquired/closed dates; else NaT\n",
    "    acquired_date = row[col_acquired] if col_acquired in row and pd.notna(row[col_acquired]) else pd.NaT\n",
    "    closed_date = row[col_closed] if col_closed in row and pd.notna(row[col_closed]) else pd.NaT\n",
    "    # pick whichever is earliest non-NaT\n",
    "    if pd.notna(acquired_date) and pd.notna(closed_date):\n",
    "        return min(acquired_date, closed_date)\n",
    "    if pd.notna(acquired_date):\n",
    "        return acquired_date\n",
    "    if pd.notna(closed_date):\n",
    "        return closed_date\n",
    "    return pd.NaT\n",
    "\n",
    "if col_founded is not None and col_founded in work_df.columns:\n",
    "    work_df[\"event_date\"] = work_df.apply(pick_event_date, axis=1)\n",
    "    work_df[\"time_to_event_days\"] = (\n",
    "        work_df[\"event_date\"] - work_df[col_founded]\n",
    "    ).dt.days\n",
    "else:\n",
    "    work_df[\"event_date\"] = pd.NaT\n",
    "    work_df[\"time_to_event_days\"] = np.nan\n",
    "\n",
    "# Missingness profile\n",
    "missing_pct = work_df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nMissingness (% of rows missing per column):\")\n",
    "print((missing_pct * 100).round(1))\n",
    "\n",
    "# Flag outliers in funding (IQR method)\n",
    "if col_funded_total is not None and col_funded_total in work_df.columns:\n",
    "    fund = work_df[col_funded_total].dropna()\n",
    "    if len(fund) > 0:\n",
    "        q1, q3 = np.percentile(fund, [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        lower = max(0, q1 - 1.5 * iqr)\n",
    "        work_df[\"funding_outlier_flag\"] = (\n",
    "            (work_df[col_funded_total] < lower) | (work_df[col_funded_total] > upper)\n",
    "        )\n",
    "        print(\n",
    "            f\"Funding IQR bounds -> lower={lower:,.0f}, upper={upper:,.0f}; \"\n",
    "            f\"outliers flagged: {work_df['funding_outlier_flag'].sum()}\"\n",
    "        )\n",
    "    else:\n",
    "        work_df[\"funding_outlier_flag\"] = False\n",
    "else:\n",
    "    work_df[\"funding_outlier_flag\"] = False\n",
    "\n",
    "# Minimal cleaning: drop rows with no name and no status\n",
    "min_keep_cols = [c for c in [col_name, col_status] if c is not None]\n",
    "if min_keep_cols:\n",
    "    before = len(work_df)\n",
    "    work_df = work_df.dropna(subset=min_keep_cols, how=\"all\")\n",
    "    print(f\"Dropped rows missing all of {min_keep_cols}: {before} -> {len(work_df)}\")\n",
    "\n",
    "# Save processed\n",
    "processed_path = PROCESSED_DIR / \"startups_crunchbase_processed.csv\"\n",
    "work_df.to_csv(processed_path, index=False)\n",
    "print(f\"\\nProcessed file written to: {processed_path}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nSummary:\")\n",
    "print({\n",
    "    \"n_rows\": len(work_df),\n",
    "    \"n_cols\": work_df.shape[1],\n",
    "    \"outcome_counts\": work_df[\"outcome_label\"].value_counts(dropna=False).to_dict() if \"outcome_label\" in work_df else {},\n",
    "})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regards to communication, we plan on using iMessage to text one anotehr. We believe this is one of the most efficient and easiest ways for us to contact one another. As for the ,essaging itself, all members have agreed to expect a rresponse, whether that be a message or a reaction, from each group member within 3 hours of the initial text being sent. We will meet twice per week, every Monday morning we will reserve a study space in the Geisel Library to meet and prodvide updates, followed by a Zoom meetimng every Friday afternoon to consolidate the designated progress from Onday's meeting. In regarcs to tone, we agree to all expect respectful interactions. Even when disagreement takes place, the person expressing the lack of approval should explain their reasonibg, as well as an alkternative method that they beleive is better. We will be concise and to the point, but still maintaining respect for one another and everyone's ideas. We plan to use voting to make decisions as a group, especially for disagreements and changes to our original plan. The project administrator will be in charge of calling teh vote, ad we will go with the majority ruling, as wel have3 5 people. We will not accept abstaining from votes. We do have specialized roles for each person, hwoever, because there is overlap, we do plan to share a lot of the responsibilties. As we are a team, we plan on heloing each other out when possible, especially if one person is struggling with a specific task. We assign roles and tasks based on the skillsets of the members, which we have laready discussed in detail. We have set a policy that struggles are inevitbale, as we are all busy. We have a guideline that whenever someone is falling behind, there is no hassle or problem in expressing that as early as possible. We would rather know what to fix earlier on in the process, rather than have a last minute lack of execution. Struggles with certain tasks hoild be expressd immediately, as we will set egos aside ti help regardless of role/assignned tasks, in roder to priotitize the team as a unit/whole.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
