{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    " Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is 0\n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|                                  | **Unsatisfactory**                                                                                                                                                                                                                                                                                                                        | **Developing**                                                                                                                                                                                                       | **Proficient**                                                                                                                                                                                            | **Excellent**                                                                                                                                                                            |\n",
    "|----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **EDA relevance**                | EDA is mostly neither relevant to the question nor helpful in figuring out how to address the question. Or the EDA does address the question, but many obviously relevant variables / analyses / figures were not included. | EDA is partly irrelevant/unhelpful. EDA missed one or two obvioulsy relevant analysis (distributions of single variables or relationships between variables) | EDA includes the obviously relevant / helpful variables in addressing the question.                                                              | Thorough EDA fully explored the dataset                                                                                                                 |\n",
    "| **EDA analysis and description** | Many of the analyses are poor choices (e.g., using means instead of medians for obviously skewed data), or are poorly described in the text, or do not aid understanding the data                                                                                                                                                     | Some of the analyses are poor choices, or are poorly described in the text, or do not aid understanding the data                                                                                                 | All analyses are correct choices. Only one or two have minor issues in the text descriptions supporting them. Mostly they fit well with other elements of the EDA and support understanding the data  | All analyses are correct choices with clear text descriptions supporting them. The figures fit well with the other elements of the EDA, producing a clear understanding of the data. |\n",
    "| **EDA figures**                  | Many of the figures are poor plot choices (e.g., using a bar plot to represent a time series where it would be better to use a line plot) or have poor aesthetics (including colormap, data point shape/color, axis labels, titles, annotations, text legibility) or do not aid understanding the data                                | Some of the figures are poor plot choices or have poor aesthetics. Some figures do not aid understanding the data                                                                                                | All figures are correct plot choices. Only one or two have minor questionable aesthetic choices. The figures mostly fit well with the other elements of the EDA and support understanding the data    | All figures are correct plot choices with beautiful aesthetics. The figures fit well with the other elements of the EDA, producing a clear understanding of the data.                |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Omar Abbasi: Project Administration, Conceptualization, Formal Analysis, Visualization, Writing – Original Draft  Zahir Ali: Conceptualization, Visualization, Software, Writing – Reviewing/Edits Adam Hamadene: Research, Formal Analysis Mostafa Darwish: Visualization, Writing – Original Draft, Data Curation Yasir Rizvi: Data Cleaning\n",
    "\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Alice Anderson: Conceptualization, Data curation, Methodology, Writing - original draft\n",
    "- Bob Barker:  Analysis, Software, Visualization\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do funding size, industry sector, and geographic location influence both the likelihood and timing of startup failure versus acquisition?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the world continues to see the intersection of human ingenuity and technological accumulation grow extremely rapidly, this shift in the corporate landscape can be tied back to a specific niche: the prevalence and growth of startups in the post-modern era. As technical knowledge and tools continue to develop, human ingenuity has found itself employed in finding the most useful ways to leverage and expand upon the current era of technology and artificial intelligence. Examples of post-modern startups include Uber, Robinhood, Stripe, Databricks, Canva, and Slack. Ideas for growth and innovation stem from all fields, and are catalyzed from a variety of sources such as corporate America, educational insititutions, and small communities all across the country. However, although the majority of the startups known today are those that found success in climbing the barrier between idea and impact, it is the majority that fall short of overcoming this hurdle and end up failing as a product. In this report, we aim to look at a multitude of variables directly and intrinsically tied to startups and their growth, to determine the coefficient of correlation between various factors such as industry sector, funding, location, and size, and how they impact a startup's ability to come to fruition. Because the growth of startups is relatively new and tied to very modern technological advancements, there is a scarce amount of research done into the causes behind their success and failures. For example, venture capital firms and startup accelerators such as Y Combinator were founded in 2005, making the funding rounds for successful startups a very new principle. Our curiosity lies in looking at the underlying details of the successes and failures for startups in the United States, as it provides an opportunity to discover findings in a modern niche that does not possess the level of academic study that other corporate fields in America do.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Startups with larger funding sizes, operating in high-growth industry sectors, and located within established entrepreneurial ecosystems are less likely to fail and tend to experience longer survival times before either failure or acquisition, whereas startups with smaller funding, in low-growth sectors, or in emerging regions face higher failure risks and shorter time-to-event durations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "- **Dataset #1 – Crunchbase Startup Investments (to 2015)**  \n",
    "  This dataset has around 50,000 (39 variables) startup records with details on their funding size, industry, location, and company status. After cleaning the dataset (removing duplicates, handling missing values, and converting funding amounts to numeric values), we created visuals such as top countries by total funding, funding amount distributions, and total VC funding over time. These results show that the U.S. dominates global funding, most startups raise relatively small amounts, and investment activity peaked around 2010–2012.  \n",
    "  Unfortunately, the dataset ends before 2015, which limits its relevance for very recent startup trends. Additionally, Crunchbase data is partly self‑reported/crowdsourced, which makes it prone to missing, biased, or inaccurate entries (especially outside U.S. and major tech hubs).\n",
    "\n",
    "- **Dataset #2 – Big Startup Success/Fail Dataset from Crunchbase**  \n",
    "  - Dataset Name: Big Startup Success/Fail Dataset from Crunchbase  \n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase  \n",
    "  - Number of observations: 24,182  \n",
    "  - Number of variables: 12  \n",
    "  - Description of the variables most relevant to this project:  \n",
    "    - Funding-related: `funding_total_usd`, `funding_rounds`, `first_funding_at`, `last_funding_at`  \n",
    "    - Outcome/status fields: `status` (operating, acquired, closed, ipo)  \n",
    "    - Company profile: `name`, `category_list`, `country_code`, `state_code`, `region`, `city`  \n",
    "    - Timing variables: `founded_at` and milestone event dates for computing time-to-failure or time-to-acquisition  \n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project:  \n",
    "    - Potential label noise: status values may be outdated; “operating” does not guarantee long-term success; “closed” labels may lag behind real closure dates.  \n",
    "    - Missing or inconsistent date fields that complicate survival/time-to-event analysis.  \n",
    "    - Possible duplicates (companies appearing multiple times under variant naming).  \n",
    "    - Inconsistent or messy industry taxonomy in `category_list`.  \n",
    "    - Survivorship and reporting bias inherent to Crunchbase data (overrepresentation of certain regions and funded companies).  \n",
    "  This dataset will be cross‑examined alongside the others because our research question is multi‑faceted and depends on both funding dynamics and outcomes.\n",
    "\n",
    "- **Dataset #3 – Startup Outcomes and Lifespan / Startup Failures datasets**  \n",
    "  These datasets document startup outcomes across multiple industries—Finance, Food, Healthcare, Information Technology, Manufacturing, and Retail—and serve as the foundation for analyzing how funding size, industry sector, and location affect a startup’s likelihood and timing of failure versus acquisition. Each record represents one startup and includes: \"Name\" – the company’s name; \"Years of Operation\" – the time span the startup was active; \"What They Did\" – a summary of the company’s primary product or service; \"How Much They Raised\" – total investor funding measured in U.S. dollars (millions); \"Why They Failed\" – a textual description of the main factor contributing to the company’s closure; and \"Takeaway\" – a concise lesson summarizing the insight learned from each company’s failure. These attributes allow us to explore patterns between financial backing, market type, and survival duration and to see whether greater funding or specific industries correlate with resilience or quicker acquisition.\n",
    "\n",
    "  Although these datasets provide valuable cross‑industry insight, they have several limitations. They focus only on startups that have failed, so they capture just one side of the entrepreneurial spectrum and overrepresent well‑documented, high‑profile companies (selection bias). As a result, smaller startups that failed quietly are likely missing, meaning our results mainly describe patterns among visible, well‑funded ventures rather than the “average” startup. The datasets also lack some quantitative details—such as geographic coordinates and detailed acquisition outcomes—that would enable a more complete analysis of survival.  \n",
    "  In terms of tidiness and cleaning, the data were mostly tidy from the start: each variable has its own column and each observation corresponds to a single startup. We mainly fixed spelling/capitalization, standardized formatting, and verified that key columns (like funding amounts) were consistently represented. Across the six sector‑specific files, there are about 409 unique observations representing startups that failed between 1992 and 2024. We kept sectors with enough observations to support meaningful comparisons and dropped rows only when absolutely necessary (e.g., to handle rare nulls or duplicates). Together, these cleaned files are saved in `data/02-processed/cleaned_dataset_3/` and combined into `Startup_Failures_clean.csv`, which we will use for cross‑sector failure and lifespan analysis.\n",
    "\n",
    "Taken together, these three datasets let us study funding patterns (Dataset #1), large‑scale status outcomes and geography (Dataset #2), and detailed failure narratives and lifespans (Dataset #3), which we will align by company, sector, and time to address our research question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:39.228016Z",
     "iopub.status.busy": "2025-12-01T05:11:39.227733Z",
     "iopub.status.idle": "2025-12-01T05:11:39.236422Z",
     "shell.execute_reply": "2025-12-01T05:11:39.236204Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import common libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup rpy2 for running R code in Python kernel\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# Note: Make sure rpy2 is installed: pip install rpy2\n",
    "# Also ensure R is installed on your system\n",
    "# Required R packages: tidyverse, ggplot2, scales, patchwork\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    " - Dataset Name: Startup Valuation Dataset\n",
    " - Link to the dataset: https://www.kaggle.com/datasets/srijan1upadhyay/startup-valuation-dataset\n",
    " - Number of observations: Computed in the code cell below (after loading)\n",
    " - Number of variables: Computed in the code cell below (after loading)\n",
    " - Description of the variables most relevant to this project:\n",
    " - Funding-related: `funding_amount_usd`, `funding_date`\n",
    " - Company profile: `company`\n",
    " - Investor information: `investor` (7 major VC firms: SoftBank, Andreessen Horowitz, Tiger Global, Index Ventures, Accel, Y Combinator, Sequoia)\n",
    " - Timing variables: `funding_date` for analyzing funding patterns and temporal trends\n",
    " - Descriptions of any shortcomings this dataset has with respect to the project:\n",
    " - Synthetic data: This is simulated data, not real-world data, limiting generalizability of models and insights\n",
    " - Limited variables: The cleaned dataset contains only 4 variables, removing important information such as industry sector, geographic location, funding round type (Series A, B, C, etc.), exit status, and operational metrics that were present in the original dataset\n",
    " - No industry or geographic information: The dataset lacks industry sector and geographic location data, making it impossible to analyze how funding patterns vary by industry or region, which is critical for understanding sector-specific success factors\n",
    " - No funding round type: The dataset does not include the type of funding round (Seed, Series A, Series B, Series C, Series D, IPO, Pre-Seed), making it impossible to analyze funding progression or understand the stage of development at which funding occurred\n",
    " - No exit status: The cleaned dataset removes exit status information, making it impossible to correlate funding patterns with startup success outcomes (IPO, acquisition, or closure)\n",
    " - Single round per record: Each observation represents one funding round, not complete funding histories, making trajectory analysis difficult\n",
    " - Limited investor diversity: Only 7 major VC firms represented, missing angel investors, corporate VCs, and smaller funds\n",
    " - Investor transparency: Lack of transparency from patent investors regarding total money raised in each series round; the dataset only shows individual funding round amounts but does not provide visibility into the complete funding picture per series, making it difficult to assess the true total capital raised across all rounds of the same series type\n",
    " - Missing series progression timeline: The dataset does not include dates for the progression of different series rounds for the same startup; without the ability to track when a startup moved from Series A to Series B to Series C, it is impossible to analyze the timing and sequence of funding rounds, which is critical for understanding startup development trajectories\n",
    " - No standardized time between rounds: There is no standardized time between funding rounds or between development stages and exit status; this makes it difficult to analyze typical development timelines, predict time-to-exit, or understand the relationship between funding frequency and startup success\n",
    " - No market context: Lacks macroeconomic indicators or industry trends at time of funding, important for predictive modeling\n",
    " - This will be cross-examined across all the datasets that we are using since our research question is multi-faceted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:39.443256Z",
     "iopub.status.busy": "2025-12-01T05:11:39.443152Z",
     "iopub.status.idle": "2025-12-01T05:11:40.099922Z",
     "shell.execute_reply": "2025-12-01T05:11:40.099325Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zahir/Downloads/startup_valuation_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the raw dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/zahir/Downloads/startup_valuation_dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Select only the columns needed for the tidy dataset\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Map: startup_name -> company, funding_date -> funding_date, \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#      funding_amount_usd -> funding_amount_usd, lead_investor -> investor\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartup_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunding_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunding_amount_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlead_investor\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zahir/Downloads/startup_valuation_dataset.csv'"
     ]
    }
   ],
   "source": [
    "## Load pre-cleaned Dataset #1 from repository\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset directly from the repository\n",
    "dataset1_df = pd.read_csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"Number of observations: {len(dataset1_df)}\")\n",
    "print(f\"Number of variables: {len(dataset1_df.columns)}\")\n",
    "print(f\"\\nColumns: {list(dataset1_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "dataset1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    " - Dataset Name: Big Startup Success/Fail Dataset from Crunchbase\n",
    " - Link to the dataset: https://www.kaggle.com/datasets/yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase\n",
    " - Number of observations: Computed in the code cell below (after loading)\n",
    " - Number of variables: Computed in the code cell below (after loading)\n",
    " - Description of the variables most relevant to this project:\n",
    " - Funding-related: `funding_total_usd`, `funding_rounds`, `first_funding_at`, `last_funding_at`\n",
    " - Outcome/status fields: `status` (operating, acquired, closed, ipo)\n",
    " - Company profile: `name`, `category_list`, `country_code`, `state_code`, `region`, `city`\n",
    " - Timing variables: `founded_at` and milestone event dates for computing time-to-failure or time-to-acquisition\n",
    " - Descriptions of any shortcomings this dataset has with respect to the project:\n",
    " - Potential label noise: status values may be outdated; \"operating\" does not guarantee long-term success; \"closed\" labels may lag behind real closure dates\n",
    " - Missing or inconsistent date fields that complicate survival/time-to-event analysis\n",
    " - Possible duplicates (companies appearing multiple times under variant naming)\n",
    " - Inconsistent or messy industry taxonomy in `category_list`\n",
    " - Survivorship and reporting bias inherent to Crunchbase data (overrepresentation of certain regions and funded companies)\n",
    " - This will be crossexmained across all the datasets that we are using since our research quesiton is multi-faceted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.101645Z",
     "iopub.status.busy": "2025-12-01T05:11:40.101547Z",
     "iopub.status.idle": "2025-12-01T05:11:40.142359Z",
     "shell.execute_reply": "2025-12-01T05:11:40.142075Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/chigagolord/Downloads/dataset2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/chigagolord/Downloads/dataset2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/chigagolord/Downloads/dataset2.csv'"
     ]
    }
   ],
   "source": [
    "## Load pre-cleaned Dataset #2 from repository\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset directly from the repository\n",
    "dataset2_df = pd.read_csv(\"data/02-processed/CleanData2.csv\")\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"Number of observations: {len(dataset2_df)}\")\n",
    "print(f\"Number of variables: {len(dataset2_df.columns)}\")\n",
    "print(f\"\\nColumns: {list(dataset2_df.columns)}\")\n",
    "dataset2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.143686Z",
     "iopub.status.busy": "2025-12-01T05:11:40.143586Z",
     "iopub.status.idle": "2025-12-01T05:11:40.154770Z",
     "shell.execute_reply": "2025-12-01T05:11:40.154551Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      2\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Data is already cleaned - show shape and info\n",
    "print(f\"Dataset shape: {dataset2_df.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(dataset2_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.156097Z",
     "iopub.status.busy": "2025-12-01T05:11:40.155992Z",
     "iopub.status.idle": "2025-12-01T05:11:40.167358Z",
     "shell.execute_reply": "2025-12-01T05:11:40.167089Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check for any missing values in the cleaned dataset\n",
    "print(\"Missing values per column:\")\n",
    "print(dataset2_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.168589Z",
     "iopub.status.busy": "2025-12-01T05:11:40.168515Z",
     "iopub.status.idle": "2025-12-01T05:11:40.179904Z",
     "shell.execute_reply": "2025-12-01T05:11:40.179648Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m non_usa \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m non_usa\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# The cleaned dataset contains only USA startups\n",
    "# Verify the country distribution\n",
    "if 'country_code' in dataset2_df.columns:\n",
    "    print(\"Country distribution:\")\n",
    "    print(dataset2_df['country_code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.181162Z",
     "iopub.status.busy": "2025-12-01T05:11:40.181079Z",
     "iopub.status.idle": "2025-12-01T05:11:40.191943Z",
     "shell.execute_reply": "2025-12-01T05:11:40.191695Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m USA_Only \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m USA_Only\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Display sample of the cleaned USA startup data\n",
    "dataset2_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.193059Z",
     "iopub.status.busy": "2025-12-01T05:11:40.192990Z",
     "iopub.status.idle": "2025-12-01T05:11:40.203636Z",
     "shell.execute_reply": "2025-12-01T05:11:40.203374Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USA_Only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m USA_Only \u001b[38;5;241m=\u001b[39m \u001b[43mUSA_Only\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermalink\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhomepage_url\u001b[39m\u001b[38;5;124m'\u001b[39m], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m USA_Only\n",
      "\u001b[0;31mNameError\u001b[0m: name 'USA_Only' is not defined"
     ]
    }
   ],
   "source": [
    "# Show status distribution of startups\n",
    "if 'status' in dataset2_df.columns:\n",
    "    print(\"Status distribution:\")\n",
    "    print(dataset2_df['status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.204951Z",
     "iopub.status.busy": "2025-12-01T05:11:40.204855Z",
     "iopub.status.idle": "2025-12-01T05:11:40.215595Z",
     "shell.execute_reply": "2025-12-01T05:11:40.215327Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USA_Only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     drop \u001b[38;5;241m=\u001b[39m USA_Only\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mvalues, axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m USA_Only[\u001b[38;5;241m~\u001b[39mdrop]\n\u001b[0;32m----> 4\u001b[0m USA_Only \u001b[38;5;241m=\u001b[39m dropper(\u001b[43mUSA_Only\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'USA_Only' is not defined"
     ]
    }
   ],
   "source": [
    "# Show funding statistics\n",
    "if 'funding_total_usd' in dataset2_df.columns:\n",
    "    print(\"Funding statistics:\")\n",
    "    print(dataset2_df['funding_total_usd'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USA_Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.217135Z",
     "iopub.status.busy": "2025-12-01T05:11:40.217018Z",
     "iopub.status.idle": "2025-12-01T05:11:40.227214Z",
     "shell.execute_reply": "2025-12-01T05:11:40.226992Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USA_Only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m USA_Only \u001b[38;5;241m=\u001b[39m \u001b[43mUSA_Only\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      2\u001b[0m USA_Only\n",
      "\u001b[0;31mNameError\u001b[0m: name 'USA_Only' is not defined"
     ]
    }
   ],
   "source": [
    "# Show state distribution\n",
    "if 'state_code' in dataset2_df.columns:\n",
    "    print(\"Top 10 states by startup count:\")\n",
    "    print(dataset2_df['state_code'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.228608Z",
     "iopub.status.busy": "2025-12-01T05:11:40.228513Z",
     "iopub.status.idle": "2025-12-01T05:11:40.235707Z",
     "shell.execute_reply": "2025-12-01T05:11:40.235470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show category distribution\n",
    "if 'category_list' in dataset2_df.columns:\n",
    "    print(\"Sample categories:\")\n",
    "    print(dataset2_df['category_list'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.236936Z",
     "iopub.status.busy": "2025-12-01T05:11:40.236850Z",
     "iopub.status.idle": "2025-12-01T05:11:40.246883Z",
     "shell.execute_reply": "2025-12-01T05:11:40.246637Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USA_Only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m USA_Only\u001b[38;5;241m=\u001b[39mcleaner(\u001b[43mUSA_Only\u001b[49m)\n\u001b[1;32m      2\u001b[0m USA_Only\n",
      "\u001b[0;31mNameError\u001b[0m: name 'USA_Only' is not defined"
     ]
    }
   ],
   "source": [
    "# Summary statistics for the cleaned dataset\n",
    "dataset2_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.248275Z",
     "iopub.status.busy": "2025-12-01T05:11:40.248187Z",
     "iopub.status.idle": "2025-12-01T05:11:40.259229Z",
     "shell.execute_reply": "2025-12-01T05:11:40.258957Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USA_Only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mUSA_Only\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleanData2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'USA_Only' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset #2 is already cleaned and saved in the repository\n",
    "# No need to save again - data is loaded from data/02-processed/CleanData2.csv\n",
    "print(\"Dataset #2 loaded successfully from: data/02-processed/CleanData2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.260483Z",
     "iopub.status.busy": "2025-12-01T05:11:40.260401Z",
     "iopub.status.idle": "2025-12-01T05:11:40.271464Z",
     "shell.execute_reply": "2025-12-01T05:11:40.271222Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USA_Only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mUSA_Only\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'USA_Only' is not defined"
     ]
    }
   ],
   "source": [
    "# Final view of the cleaned dataset\n",
    "dataset2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #3 - Startup Outcomes and Lifespan Dataset\n",
    "\n",
    "These datasets document startup outcomes across multiple industries—Finance, Food, Healthcare, Information Technology, Manufacturing, and Retail—and serve as the foundation for analyzing how funding size, industry sector, and location affect a startup’s likelihood and timing of failure versus acquisition. Each record represents one startup and includes: \"Name\" – the company’s name. \"Years of Operation\" – the time span the startup was active (in years). \"What They Did\" – a categorical summary of the company’s primary product or service. \"How Much They Raised\" – total investor funding measured in U.S. dollars (millions). For instance, $500M represents five hundred million dollars raised from venture capital or private investors. \"Why They Failed\" – a textual description of the main factor contributing to the company’s closure, such as competition, market shifts, regulatory pressure, or loss of funding. \"Takeaway\" – a concise lesson summarizing the insight learned from each company’s failure (e.g., “Crypto needs stability” or “Finance apps need edge”). These attributes allow us to explore patterns between financial backing, market type, and survival duration, revealing whether greater funding or specific industries correlate with resilience or quicker acquisition. By analyzing the timing between founding and shutdown years, we can quantify “startup lifespan” and compare it across sectors.\n",
    "\n",
    "Although these datasets provide valuable cross-industry insight, they are subject to several limitations. One main one is that the dataset only focuses on startups that have failed , meaning it only captures one side of the entrepreneurial spectrum. The data is sourced from CB Insights' \"Startup Failure Post-Mortem\" compilation, which highlights well documented and often high profile companies. Because of this, the sample is not random or representative of all startups which implies that smaller companies that failed quietly are likely missing. This creates a form of selection bias because of how our data only includes visible startups, so our results will mainly describe patterns among high-profile, well-funded ventures, not the average startup. While this selection bias limits the dataset’s ability to compare success versus failure rates directly, it does not invalidate its usefulness for the research question. Also, our dataset lacks certain quanatative details, for example, geographic coordinates and aquisition outcomes, that would allow for a more complete analysis of startup survival.\n",
    "\n",
    "To make our dataset tidy, it was mainly tidy to begin with upon inspection. Every variable inside the dataset had its own column and each observation represented a single startup. There was not a single cell, hich contained multiple variables or lists, meaning the data was classified as tidy to begin with. A part from that, we fixed spelling/capitalization errors and overall formatting to make it more neat and feasible to utilize. Furthermore, across all six sector-specific datasets or files (Finance, Food, Healthcare, Information, Manufacturing, and Retail), there were a total of there were a total of 409 unqiue observations. Each observation that was included corresponded o one startup that failed between 1992 and 2024. We mainly focused on the six core sectors, which I previously mentioned beforehand, mainly because we wanted to ensure greater consistency, comparability, and data quality across industries. The remaining observations or entries were excluded because they either lacked sufficient information in key variables, or they represented industries with too few startups to extract menaingful insights out of. Moreover, a null-value check (df.isna().sum()) showed that the dataset had minimal missing values or data overall. Most columns were complete, with occassional missing entries in certain columns (like \"Takeaway\" and \"Why They Failed\"). These missing values would appear at random, as they did not correspond systematically to particular industries or funding rates. The main outliers in our dataset were checked in the \"How Much They Raise\" column through value inspection. Some companies were reported absurdily high funding of over and equal $1B, but these are legitimate outliers that represents large funded startups (like those in the finance sector). These values are primarily real rather than errors, they are kept to preserve the dataset's accuracy. Lastly, the datasets were generally clean and needed minor formatting changes (like adding underscores whenever there was a space, removing any trailing whitespace, and verifying all funding amounts using consistent dollar format). The dataset was nearly clean, complete, and missingness was very rare to begin with, so no rows were dropped. However, we still utilized the .dropna() just in case any null values were present, and we utlized the drop_duplicates to drop any duplicates that may have been present.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.272734Z",
     "iopub.status.busy": "2025-12-01T05:11:40.272656Z",
     "iopub.status.idle": "2025-12-01T05:11:40.287588Z",
     "shell.execute_reply": "2025-12-01T05:11:40.287353Z"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "finance_df = pd.read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failure_Finance_clean.csv\")\n",
    "food_df = pd.read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failure_Food_clean.csv\")\n",
    "healthcare_df = pd.read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failure_Healthcare_Clean.csv\")\n",
    "info_df = pd.read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failure_Information_Clean.csv\")\n",
    "manufactures_df = pd.read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failure_Manufactures_Clean.csv\")\n",
    "retail_df = pd.read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failure_Retail_Clean.csv\")\n",
    "all_df = pd.read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failures_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.289278Z",
     "iopub.status.busy": "2025-12-01T05:11:40.289167Z",
     "iopub.status.idle": "2025-12-01T05:11:40.312236Z",
     "shell.execute_reply": "2025-12-01T05:11:40.311970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Years of Operation</th>\n",
       "      <th>What They Did</th>\n",
       "      <th>How Much They Raised</th>\n",
       "      <th>Why They Failed</th>\n",
       "      <th>Takeaway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avant</td>\n",
       "      <td>2012-2023</td>\n",
       "      <td>Online personal loans</td>\n",
       "      <td>$655M</td>\n",
       "      <td>Lost to LendingClub and high defaults</td>\n",
       "      <td>Lending needs risk balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitpass</td>\n",
       "      <td>2002-2008</td>\n",
       "      <td>Micropayments platform</td>\n",
       "      <td>$2M</td>\n",
       "      <td>Lost to PayPal and low adoption</td>\n",
       "      <td>Micropayments need mass use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cake Financial</td>\n",
       "      <td>2006-2011</td>\n",
       "      <td>Portfolio tracking tool</td>\n",
       "      <td>$3M</td>\n",
       "      <td>Lost to Mint and sold to TradeKing</td>\n",
       "      <td>Finance tools need scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Circle</td>\n",
       "      <td>2013-2023</td>\n",
       "      <td>Crypto payments and stablecoin</td>\n",
       "      <td>$500M</td>\n",
       "      <td>Lost to Coinbase and market shifts</td>\n",
       "      <td>Crypto needs stability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clarity Money</td>\n",
       "      <td>2016-2022</td>\n",
       "      <td>Personal finance app</td>\n",
       "      <td>$11M</td>\n",
       "      <td>Lost to Mint/Acorns and sold to Goldman</td>\n",
       "      <td>Finance apps need edge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Years of Operation                   What They Did  \\\n",
       "0           Avant          2012-2023           Online personal loans   \n",
       "1         Bitpass          2002-2008          Micropayments platform   \n",
       "2  Cake Financial          2006-2011         Portfolio tracking tool   \n",
       "3          Circle          2013-2023  Crypto payments and stablecoin   \n",
       "4   Clarity Money          2016-2022            Personal finance app   \n",
       "\n",
       "  How Much They Raised                          Why They Failed  \\\n",
       "0                $655M    Lost to LendingClub and high defaults   \n",
       "1                  $2M          Lost to PayPal and low adoption   \n",
       "2                  $3M       Lost to Mint and sold to TradeKing   \n",
       "3                $500M       Lost to Coinbase and market shifts   \n",
       "4                 $11M  Lost to Mint/Acorns and sold to Goldman   \n",
       "\n",
       "                      Takeaway  \n",
       "0   Lending needs risk balance  \n",
       "1  Micropayments need mass use  \n",
       "2     Finance tools need scale  \n",
       "3       Crypto needs stability  \n",
       "4       Finance apps need edge  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>what_they_did</th>\n",
       "      <th>why_they_failed</th>\n",
       "      <th>takeaway</th>\n",
       "      <th>how_much_they_raised</th>\n",
       "      <th>years_of_operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cafe X</td>\n",
       "      <td>Robotic coffee kiosks</td>\n",
       "      <td>Closed 2021; low adoption; lost to Starbucks</td>\n",
       "      <td>Humans trump robots</td>\n",
       "      <td>$15M</td>\n",
       "      <td>6 (2015-2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caviar</td>\n",
       "      <td>Premium food delivery</td>\n",
       "      <td>Sold 2020; couldn't scale; lost to DoorDash</td>\n",
       "      <td>Premium loses to scale</td>\n",
       "      <td>$90M</td>\n",
       "      <td>8 (2012-2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chef'd</td>\n",
       "      <td>Meal kit delivery</td>\n",
       "      <td>Closed 2019; high costs; lost to Blue Apron</td>\n",
       "      <td>Costs cook meal kits</td>\n",
       "      <td>$35M</td>\n",
       "      <td>5 (2014-2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChowNow</td>\n",
       "      <td>Restaurant ordering platform</td>\n",
       "      <td>Faded 2023; lost to DoorDash</td>\n",
       "      <td>Middlemen get squeezed</td>\n",
       "      <td>$64M</td>\n",
       "      <td>12 (2011-2023)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clover</td>\n",
       "      <td>Plant-based fast food chain</td>\n",
       "      <td>Closed 2020; niche; lost to McDonald's</td>\n",
       "      <td>Niche eats need taste</td>\n",
       "      <td>$20M</td>\n",
       "      <td>8 (2012-2020)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                 what_they_did  \\\n",
       "0   Cafe X         Robotic coffee kiosks   \n",
       "1   Caviar         Premium food delivery   \n",
       "2   Chef'd             Meal kit delivery   \n",
       "3  ChowNow  Restaurant ordering platform   \n",
       "4   Clover   Plant-based fast food chain   \n",
       "\n",
       "                                why_they_failed                takeaway  \\\n",
       "0  Closed 2021; low adoption; lost to Starbucks     Humans trump robots   \n",
       "1   Sold 2020; couldn't scale; lost to DoorDash  Premium loses to scale   \n",
       "2   Closed 2019; high costs; lost to Blue Apron    Costs cook meal kits   \n",
       "3                  Faded 2023; lost to DoorDash  Middlemen get squeezed   \n",
       "4        Closed 2020; niche; lost to McDonald's   Niche eats need taste   \n",
       "\n",
       "  how_much_they_raised years_of_operation  \n",
       "0                 $15M      6 (2015-2021)  \n",
       "1                 $90M      8 (2012-2020)  \n",
       "2                 $35M      5 (2014-2019)  \n",
       "3                 $64M     12 (2011-2023)  \n",
       "4                 $20M      8 (2012-2020)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Healthcare Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years_of_operation</th>\n",
       "      <th>what_they_did</th>\n",
       "      <th>how_much_they_raised</th>\n",
       "      <th>why_they_failed</th>\n",
       "      <th>takeaway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aira Health</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>Personalized asthma/allergy app</td>\n",
       "      <td>$12M</td>\n",
       "      <td>Small user base and cash shortage</td>\n",
       "      <td>Niche apps need big audiences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amino</td>\n",
       "      <td>2013-2021</td>\n",
       "      <td>Doctor search and cost estimation</td>\n",
       "      <td>$45M</td>\n",
       "      <td>Lost to Zocdoc/GoodRx and slow adoption</td>\n",
       "      <td>Narrow focus beats broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arivale</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>Personalized health coaching</td>\n",
       "      <td>$50M</td>\n",
       "      <td>High costs and low demand</td>\n",
       "      <td>Premium needs mass market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Augmedix</td>\n",
       "      <td>2012-2024</td>\n",
       "      <td>Remote medical scribes</td>\n",
       "      <td>$150M</td>\n",
       "      <td>Lost to software rivals and acquired</td>\n",
       "      <td>Flexibility beats rigidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avizia</td>\n",
       "      <td>2014-2018</td>\n",
       "      <td>Telemedicine for hospitals</td>\n",
       "      <td>$32M</td>\n",
       "      <td>Outpaced by bigger rivals and acquired</td>\n",
       "      <td>Niche needs a moat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name years_of_operation                      what_they_did  \\\n",
       "0  Aira Health          2015-2019    Personalized asthma/allergy app   \n",
       "1        Amino          2013-2021  Doctor search and cost estimation   \n",
       "2      Arivale          2015-2019       Personalized health coaching   \n",
       "3     Augmedix          2012-2024             Remote medical scribes   \n",
       "4       Avizia          2014-2018         Telemedicine for hospitals   \n",
       "\n",
       "  how_much_they_raised                          why_they_failed  \\\n",
       "0                 $12M        Small user base and cash shortage   \n",
       "1                 $45M  Lost to Zocdoc/GoodRx and slow adoption   \n",
       "2                 $50M                High costs and low demand   \n",
       "3                $150M     Lost to software rivals and acquired   \n",
       "4                 $32M   Outpaced by bigger rivals and acquired   \n",
       "\n",
       "                        takeaway  \n",
       "0  Niche apps need big audiences  \n",
       "1       Narrow focus beats broad  \n",
       "2      Premium needs mass market  \n",
       "3     Flexibility beats rigidity  \n",
       "4             Niche needs a moat  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years_of_operation</th>\n",
       "      <th>what_they_did</th>\n",
       "      <th>how_much_they_raised</th>\n",
       "      <th>why_they_failed</th>\n",
       "      <th>takeaway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airy Labs</td>\n",
       "      <td>2 (2010-2012)</td>\n",
       "      <td>Educational mobile games for kids</td>\n",
       "      <td>$1.5M</td>\n",
       "      <td>Shut down in 2012 after chaotic sprint; too ma...</td>\n",
       "      <td>Focus beats frenzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ask Jeeves</td>\n",
       "      <td>11 (1996-2007)</td>\n",
       "      <td>Early search engine with butler mascot</td>\n",
       "      <td>$20M</td>\n",
       "      <td>Faded by 2007; lost to Google's algorithm and ...</td>\n",
       "      <td>Innovation isn't enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bebo</td>\n",
       "      <td>14 (2005-2019)</td>\n",
       "      <td>Social networking site popular in UK</td>\n",
       "      <td>$12.8M</td>\n",
       "      <td>Shut down in 2019; lost to Facebook; AOL misma...</td>\n",
       "      <td>Network effects can crush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burbn</td>\n",
       "      <td>2 (2010-2012)</td>\n",
       "      <td>Check-in app with photo-sharing</td>\n",
       "      <td>$0.5M</td>\n",
       "      <td>Closed in 2012 but pivoted to Instagram; too c...</td>\n",
       "      <td>Pivots can save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canvas</td>\n",
       "      <td>6 (2011-2017)</td>\n",
       "      <td>Collaborative document editing platform</td>\n",
       "      <td>$9M</td>\n",
       "      <td>Shut down in 2017; lost to Google Docs; Dropbo...</td>\n",
       "      <td>Stand out or drown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name years_of_operation                            what_they_did  \\\n",
       "0   Airy Labs      2 (2010-2012)        Educational mobile games for kids   \n",
       "1  Ask Jeeves     11 (1996-2007)   Early search engine with butler mascot   \n",
       "2        Bebo     14 (2005-2019)     Social networking site popular in UK   \n",
       "3       Burbn      2 (2010-2012)          Check-in app with photo-sharing   \n",
       "4      Canvas      6 (2011-2017)  Collaborative document editing platform   \n",
       "\n",
       "  how_much_they_raised                                    why_they_failed  \\\n",
       "0                $1.5M  Shut down in 2012 after chaotic sprint; too ma...   \n",
       "1                 $20M  Faded by 2007; lost to Google's algorithm and ...   \n",
       "2               $12.8M  Shut down in 2019; lost to Facebook; AOL misma...   \n",
       "3                $0.5M  Closed in 2012 but pivoted to Instagram; too c...   \n",
       "4                  $9M  Shut down in 2017; lost to Google Docs; Dropbo...   \n",
       "\n",
       "                    takeaway  \n",
       "0         Focus beats frenzy  \n",
       "1    Innovation isn't enough  \n",
       "2  Network effects can crush  \n",
       "3            Pivots can save  \n",
       "4         Stand out or drown  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manufactures Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years_of_operation</th>\n",
       "      <th>what_they_did</th>\n",
       "      <th>how_much_they_raised</th>\n",
       "      <th>why_they_failed</th>\n",
       "      <th>takeaway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airware</td>\n",
       "      <td>2011-2018</td>\n",
       "      <td>Drone hardware/software for industry</td>\n",
       "      <td>$70M</td>\n",
       "      <td>Lost to DJI and high costs</td>\n",
       "      <td>Drones need simplicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anki</td>\n",
       "      <td>2010-2019</td>\n",
       "      <td>AI-powered toy robots</td>\n",
       "      <td>$200M</td>\n",
       "      <td>High costs and competition from Lego/Sphero</td>\n",
       "      <td>Consumer hardware needs mass pricing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aptera Motors</td>\n",
       "      <td>2005-2011</td>\n",
       "      <td>Three-wheeled electric vehicles</td>\n",
       "      <td>$40M</td>\n",
       "      <td>Lost to Tesla and quirky design</td>\n",
       "      <td>EVs need mainstream appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aria Insights</td>\n",
       "      <td>2008-2019</td>\n",
       "      <td>Tethered industrial drones</td>\n",
       "      <td>$39M</td>\n",
       "      <td>Small market and lost to DJI/Skydio</td>\n",
       "      <td>Hardware niches need big adopters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August Home</td>\n",
       "      <td>2012-2017</td>\n",
       "      <td>Smart locks and doorbells</td>\n",
       "      <td>$73M</td>\n",
       "      <td>Lost to Ring/Nest and acquired</td>\n",
       "      <td>Smart home needs ecosystem power</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name years_of_operation                         what_they_did  \\\n",
       "0        Airware          2011-2018  Drone hardware/software for industry   \n",
       "1           Anki          2010-2019                 AI-powered toy robots   \n",
       "2  Aptera Motors          2005-2011       Three-wheeled electric vehicles   \n",
       "3  Aria Insights          2008-2019            Tethered industrial drones   \n",
       "4    August Home          2012-2017             Smart locks and doorbells   \n",
       "\n",
       "  how_much_they_raised                              why_they_failed  \\\n",
       "0                 $70M                   Lost to DJI and high costs   \n",
       "1                $200M  High costs and competition from Lego/Sphero   \n",
       "2                 $40M              Lost to Tesla and quirky design   \n",
       "3                 $39M          Small market and lost to DJI/Skydio   \n",
       "4                 $73M               Lost to Ring/Nest and acquired   \n",
       "\n",
       "                               takeaway  \n",
       "0                Drones need simplicity  \n",
       "1  Consumer hardware needs mass pricing  \n",
       "2            EVs need mainstream appeal  \n",
       "3     Hardware niches need big adopters  \n",
       "4      Smart home needs ecosystem power  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retail Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years_of_operation</th>\n",
       "      <th>what_they_did</th>\n",
       "      <th>how_much_they_raised</th>\n",
       "      <th>why_they_failed</th>\n",
       "      <th>takeaway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99dresses</td>\n",
       "      <td>3 (2010-2013)</td>\n",
       "      <td>Fashion swapping app</td>\n",
       "      <td>$0.5M</td>\n",
       "      <td>Shut down 2013; low retention; funding fell th...</td>\n",
       "      <td>Retention is king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahalife</td>\n",
       "      <td>7 (2010-2017)</td>\n",
       "      <td>Curated luxury goods marketplace</td>\n",
       "      <td>$20M</td>\n",
       "      <td>Closed 2017; high marketing costs; lost to Amazon</td>\n",
       "      <td>Niche doesn't defend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AllRomance</td>\n",
       "      <td>10 (2006-2016)</td>\n",
       "      <td>E-book retailer for romance novels</td>\n",
       "      <td>$1M</td>\n",
       "      <td>Closed 2016; financial losses; lost to Kindle</td>\n",
       "      <td>Adapt or die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auctionata</td>\n",
       "      <td>6 (2012-2018)</td>\n",
       "      <td>Online auction house for art and luxury</td>\n",
       "      <td>$95M</td>\n",
       "      <td>Shut down 2018; high costs; lost to eBay; valu...</td>\n",
       "      <td>Trust and economics matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Augury Books</td>\n",
       "      <td>5 (2012-2017)</td>\n",
       "      <td>Indie e-commerce bookstore for poetry</td>\n",
       "      <td>$0.5M</td>\n",
       "      <td>Closed 2017; couldn't scale; lost to Amazon</td>\n",
       "      <td>Niche retail bleeds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name years_of_operation                            what_they_did  \\\n",
       "0     99dresses      3 (2010-2013)                     Fashion swapping app   \n",
       "1       Ahalife      7 (2010-2017)         Curated luxury goods marketplace   \n",
       "2    AllRomance     10 (2006-2016)       E-book retailer for romance novels   \n",
       "3    Auctionata      6 (2012-2018)  Online auction house for art and luxury   \n",
       "4  Augury Books      5 (2012-2017)    Indie e-commerce bookstore for poetry   \n",
       "\n",
       "  how_much_they_raised                                    why_they_failed  \\\n",
       "0                $0.5M  Shut down 2013; low retention; funding fell th...   \n",
       "1                 $20M  Closed 2017; high marketing costs; lost to Amazon   \n",
       "2                  $1M      Closed 2016; financial losses; lost to Kindle   \n",
       "3                 $95M  Shut down 2018; high costs; lost to eBay; valu...   \n",
       "4                $0.5M        Closed 2017; couldn't scale; lost to Amazon   \n",
       "\n",
       "                     takeaway  \n",
       "0           Retention is king  \n",
       "1        Niche doesn't defend  \n",
       "2                Adapt or die  \n",
       "3  Trust and economics matter  \n",
       "4         Niche retail bleeds  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Startups Combined Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Years</th>\n",
       "      <th>Period</th>\n",
       "      <th>Start_Year</th>\n",
       "      <th>End_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99dresses</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>3</td>\n",
       "      <td>(2010-2013)</td>\n",
       "      <td>2010</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahalife</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>7</td>\n",
       "      <td>(2010-2017)</td>\n",
       "      <td>2010</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airy Labs</td>\n",
       "      <td>Information</td>\n",
       "      <td>2</td>\n",
       "      <td>(2010-2012)</td>\n",
       "      <td>2010</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AllRomance</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>10</td>\n",
       "      <td>(2006-2016)</td>\n",
       "      <td>2006</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ampush</td>\n",
       "      <td>Professional Scientific and Technical Services</td>\n",
       "      <td>13</td>\n",
       "      <td>(2010-2023)</td>\n",
       "      <td>2010</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name                                          Sector  Years  \\\n",
       "0   99dresses                                    Retail Trade      3   \n",
       "1     Ahalife                                    Retail Trade      7   \n",
       "2   Airy Labs                                     Information      2   \n",
       "3  AllRomance                                    Retail Trade     10   \n",
       "4      Ampush  Professional Scientific and Technical Services     13   \n",
       "\n",
       "        Period  Start_Year  End_Year  \n",
       "0  (2010-2013)        2010      2013  \n",
       "1  (2010-2017)        2010      2017  \n",
       "2  (2010-2012)        2010      2012  \n",
       "3  (2006-2016)        2006      2016  \n",
       "4  (2010-2023)        2010      2023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print(\"Finance Dataset:\")\n",
    "display(finance_df.head())\n",
    "\n",
    "print(\"\\nFood Dataset:\")\n",
    "display(food_df.head())\n",
    "\n",
    "print(\"\\nHealthcare Dataset:\")\n",
    "display(healthcare_df.head())\n",
    "\n",
    "print(\"\\nInformation Dataset:\")\n",
    "display(info_df.head())\n",
    "\n",
    "print(\"\\nManufactures Dataset:\")\n",
    "display(manufactures_df.head())\n",
    "\n",
    "print(\"\\nRetail Dataset:\")\n",
    "display(retail_df.head())\n",
    "\n",
    "print(\"\\nAll Startups Combined Dataset:\")\n",
    "display(all_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T05:11:40.313683Z",
     "iopub.status.busy": "2025-12-01T05:11:40.313557Z",
     "iopub.status.idle": "2025-12-01T05:11:40.321263Z",
     "shell.execute_reply": "2025-12-01T05:11:40.320987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import for displaying images\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "Our exploratory data analysis focused on how funding, industry, geography, and network structure jointly shape startup outcomes, particularly acquisition versus closure. Across multiple visualizations, we consistently observed that higher funding levels are associated with higher acquisition rates, but that capital alone is not sufficient to guarantee survival. Sector-level trends showed that Consumer & Media and Software & Web startups tend to achieve the strongest “success trajectories,” while Life Sciences and other hardware-adjacent sectors exhibit more modest gains per funding tier. Network-based analyses revealed an even stronger relationship: startups with denser connections to “notable” individuals—board members, VC partners, experienced founders, and media contacts—show sharply higher acquisition rates, suggesting that relational capital amplifies the impact of financial capital.\n",
    "Geographic visualizations highlighted the outsized role of California and a handful of coastal states. California not only hosts the greatest density of startups but also contributes a disproportionate share of successful acquisitions, likely reflecting the concentration of venture capital firms, accelerators, and large tech incumbents. Survival-curve and failure-focused plots (e.g., the “valley of death” analysis) further showed that many well-funded startups still fail during a critical 3–7 year window, emphasizing that competition, execution, and market fit dominate beyond simple funding totals. Finally, comparison plots between acquired and closed companies demonstrated that while acquired startups have somewhat higher total funding and more rounds, the distributions overlap heavily—indicating that sustained fundraising momentum and strategic progression through later-stage rounds matter more than any single large check. All visualizations in this section were produced in RStudio using R; we intentionally do not include the underlying R code in this notebook, and instead focus here on documenting the resulting patterns, interpretations, and how they inform our subsequent modeling and analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# R LIBRARY IMPORTS FOR DATA VISUALIZATIONS\n",
    "# ============================================================================\n",
    "# This cell loads all necessary R libraries for the EDA visualizations\n",
    "# Make sure rpy2 is set up (run the setup cell earlier in the notebook)\n",
    "\n",
    "%%R\n",
    "\n",
    "# Core data manipulation and visualization libraries\n",
    "library(tidyverse)  # Includes dplyr, ggplot2, and other essential packages\n",
    "library(ggplot2)    # Grammar of graphics for creating plots\n",
    "library(scales)      # Scale functions for better axis formatting\n",
    "library(patchwork)   # Combining multiple plots\n",
    "\n",
    "# Additional useful libraries (uncomment if needed)\n",
    "# library(readr)      # Fast reading of CSV files\n",
    "# library(dplyr)      # Data manipulation (included in tidyverse)\n",
    "# library(tidyr)      # Data tidying (included in tidyverse)\n",
    "\n",
    "cat(\"✓ All R libraries loaded successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-success_trajectories_by_industry"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Success Trajectories by Industry\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Success Trajectories by Industry\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"success_trajectories_by_industry.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Success Trajectories by Industry\n",
    "Omar: Graph 1 visualizes how acquisition outcomes vary across funding levels and industry sectors for U.S. startups between 2015 and 2025. Each point in the figure represents a funding–sector intersection, and the acquisition rate captures the share of startups in that cell that are bought by a larger parent company. \n",
    "\n",
    "Across the five major sectors we highlight (Consumer & Media, Enterprise & Hardware, Life Sciences, Software & Web, and an “Other” category that largely refers to semiconductors, security, and hardware-adjacent firms), there is a clear upward trend: higher funding levels are consistently associated with higher acquisition rates. This strong positive correlation suggests that capital is an intrinsic catalyst for startup “success” (as measured by acquisition) regardless of industry. \n",
    "\n",
    "Given this pattern, our subsequent analyses focus on understanding how startups reach these higher funding tiers and which secondary or tertiary characteristics—such as geography, number of rounds, and sector niche—coincide with both greater funding and improved survival or acquisition trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-success_trajectories_by_network_strength"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Network Strength as a Catalyst for Startup Acquisition Success\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Network Strength as a Catalyst for Startup Acquisition Success\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"success_trajectories_by_network_strength.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Strength as a Catalyst for Startup Acquisition Success\n",
    "\n",
    "Omar Graph 2: In order to build off of the aforementioned visualization regarding industry, funding, and success, our focus has concentrated onto the characteristics that lead to higher funding levels for domestic startups. One of those qualities/measurements is the network strength of these startups, which is measured by the total number of relationships to “notable” individuals. This system refers to the numerical count of how many documented relationships the startup has with sitting board members of larger enterprises, which can include executives at larger companies, advisors at venture capital firms, key executives such as other founders, as well as the total mentions and connections that the startup has to advertising branches and the press. The most notable takeaway from the visualization is that the relationship between network strength and acquisition rate has an even stronger positive linear correlation in comparison to funding and acquisition rate, and all sectors except for “other” show a positive linear correlation as well. \n",
    "\n",
    "When considering the previous two visualizations holistically, the primary takeaway is that stronger funding and networks are highly correlated with a higher success rate, as measured by acquisition status. When considering the two from a logical standpoint, the primary takeaway would be that as funding and network strength work intrinsically to drive success of startups, founders and executives from startup companies with ideas at scale should be actively seeking the greatest opportunities to strengthen their networks and receive more funding for their scaling processes. These two work hand in hand, as stronger networks with venture capitalists and outside executives can not only directly lead to a greater influx of investment, but also opportunities for more recognition and interest from other executives and investors, creating a strong pipeline for investments and success moving forwards. One factor which we can further look into to understand how these startups look to maximize networks and funding together could be through where they are located during their production, as the surrounding environment is a massive gateway towards building connections and networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-startup_density_across_america"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Startup density across America\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Startup density across America\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"startup_density_across_america.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Startup density across America\n",
    "Omar Graph 3: As mentioned, we are aiming to look into the geographic factor behind startups, and how this may tie into driving success through network strength and funding. As seen in the graph, California dominates the startup scene with over 480 startups in total still active within the state. From this, it can be deduced that California has produced the best environment for startups to set up and grow. Next, we will provide a breakdown of how these states stack up in terms of success rate of the startups present in this visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-top_10_states_startup_outcomes"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Top 10 States: Startup Outcomes\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Top 10 States: Startup Outcomes\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"top_10_states_startup_outcomes.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 States: Startup Outcomes\n",
    "Omar Graph 4: As we have broken down the success rates by state, the top 5 are Massachusetts, New York, Colorado, California, and Washington. However, the most striking outcome from the visualization itself is the sheer magnitude of the volume of startups in California. While the ratio of success may be lower in total, they contribute over half of the total number of acquired startups in the United States. To tie this back into the original question of how funding, success, industry, and geographic location affect success, it can be inferred that California likely provides the best surrounding environment for startup success, primarily based upon greater opportunities for funding and stronger relationships. As California is home to multiple venture capital firms and startup accelerators such as YCombinator and Avenir Growth, alongside the Silicon Valley bank, it is no surprise that California has cultivated the stronger startup culture in the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-total_funding_by_category"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Total Funding by Category (in Millions)\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Total Funding by Category (in Millions)\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"total_funding_by_category.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Funding by Category (in Millions)\n",
    "Omar Graph 5: The singular factor which we have not fully touched on yet is the industry sector. Here, we aim to depict the funding success of startups by industry, as well as the separation of the failed and successful startups by acquisition for each industry itself. The correlation between funding and success is once again prevalent, as the size of the squares on the treemap correlate to higher funding, and the acquired section takes up just over 75% of the axes in total. In relation to industries, however, the dominant industries for success are mobile, software, and web. An important note is that the “Mobile” sector includes any startup company that possesses a primary product launch through mobile-based platforms, mainly apps. Examples of these include DoorDash, Uber Eats, and Wire. These companies tend to be very highly funded, and also very successful. A secondary factor we can consider within this concept in relation to extrapolating our work into the future is conjuring how automation and the AI explosion over the past two years can impact these findings and trajectories. Certain industries such as advertising are already being siphoned by artificial intelligence based platforms, as Google and Meta Ads have become a hotspot for automation companies to sell algorithmic advertisement automation to consumers across the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-the_valley_of_death"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VALLEY OF DEATH - DATA-DRIVEN SURVIVAL CURVE FOR RSTUDIO\n",
    "# ============================================================================\n",
    "# \n",
    "# This script creates a survival curve visualization showing actual startup \n",
    "# failure patterns from the dataset - a true representation backed by real data.\n",
    "# \n",
    "# Required packages: tidyverse, ggplot2, scales, patchwork\n",
    "# ============================================================================\n",
    "\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "library(patchwork)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "BACKGROUND_COLOR <- \"#1e2738\"\n",
    "GRID_COLOR <- \"#3a4555\"\n",
    "TEXT_COLOR <- \"#ffffff\"\n",
    "SUBTITLE_COLOR <- \"#8899aa\"\n",
    "AXIS_COLOR <- \"#a0aec0\"\n",
    "\n",
    "COLORS <- list(\n",
    "  extreme_danger = \"#dc2626\",\n",
    "  high_risk = \"#ea580c\",\n",
    "  moderate_risk = \"#f97316\",\n",
    "  caution = \"#facc15\",\n",
    "  improving = \"#84cc16\",\n",
    "  safe_zone = \"#22c55e\",\n",
    "  funding_gap = \"#dc2626\",\n",
    "  stage_default = \"#374151\",\n",
    "  milestone = \"#fbbf24\",\n",
    "  curve = \"#ffffff\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# THEME\n",
    "# ============================================================================\n",
    "\n",
    "theme_dark_dashboard <- function() {\n",
    "  theme_minimal(base_size = 14) +\n",
    "    theme(\n",
    "      plot.background = element_rect(fill = BACKGROUND_COLOR, color = NA),\n",
    "      panel.background = element_rect(fill = BACKGROUND_COLOR, color = NA),\n",
    "      panel.grid.major.y = element_line(color = GRID_COLOR, linewidth = 0.3),\n",
    "      panel.grid.major.x = element_line(color = GRID_COLOR, linewidth = 0.2, linetype = \"dotted\"),\n",
    "      panel.grid.minor = element_blank(),\n",
    "      text = element_text(color = TEXT_COLOR),\n",
    "      axis.text = element_text(color = AXIS_COLOR, size = 11),\n",
    "      axis.title = element_text(color = TEXT_COLOR, face = \"bold\", size = 13),\n",
    "      legend.background = element_rect(fill = \"transparent\", color = NA),\n",
    "      legend.text = element_text(color = TEXT_COLOR, size = 10),\n",
    "      plot.margin = margin(15, 20, 15, 20),\n",
    "      axis.line = element_blank(),\n",
    "      axis.ticks = element_blank()\n",
    "    )\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "cat(\"Loading data...\\n\")\n",
    "\n",
    "# UPDATE THIS PATH to your local file\n",
    "df <- read_csv(\"data/02-processed/cleaned_dataset_3/Startup_Failures_clean.csv\", show_col_types = FALSE)\n",
    "\n",
    "# Extract years\n",
    "df <- df %>%\n",
    "  mutate(\n",
    "    Start_Year = as.numeric(str_extract(`Years.of.Operation`, \"\\\\d{4}\")),\n",
    "    End_Year = as.numeric(str_extract(`Years.of.Operation`, \"\\\\d{4}$\")),\n",
    "    Years_Active = End_Year - Start_Year\n",
    "  ) %>%\n",
    "  filter(!is.na(Years_Active), Years_Active >= 0, Years_Active <= 15)\n",
    "\n",
    "total_startups <- nrow(df)\n",
    "cat(\"Total companies analyzed:\", total_startups, \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATE SURVIVAL STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "# Count failures at each year\n",
    "failure_counts <- df %>%\n",
    "  count(Years_Active, name = \"failures\") %>%\n",
    "  complete(Years_Active = 0:15, fill = list(failures = 0)) %>%\n",
    "  arrange(Years_Active) %>%\n",
    "  mutate(\n",
    "    cumulative_failures = cumsum(failures),\n",
    "    survivors = total_startups - cumulative_failures,\n",
    "    survival_rate = survivors / total_startups * 100,\n",
    "    failure_rate = failures / total_startups * 100\n",
    "  )\n",
    "\n",
    "cat(\"\\nSurvival Data:\\n\")\n",
    "print(failure_counts)\n",
    "\n",
    "# ============================================================================\n",
    "# TITLE PLOT\n",
    "# ============================================================================\n",
    "\n",
    "p_title <- ggplot() +\n",
    "  annotate(\"text\", x = 0.5, y = 0.7, \n",
    "           label = \"the Valley of Death\",\n",
    "           color = TEXT_COLOR, size = 11, fontface = \"bold\") +\n",
    "  annotate(\"text\", x = 0.5, y = 0.25,\n",
    "           label = paste0(\"Survival curve based on \", total_startups, \" startup failures\"),\n",
    "           color = SUBTITLE_COLOR, size = 4.5) +\n",
    "  xlim(0, 1) + ylim(0, 1) +\n",
    "  theme_void() +\n",
    "  theme(plot.background = element_rect(fill = BACKGROUND_COLOR, color = NA),\n",
    "        plot.margin = margin(15, 25, 0, 25))\n",
    "\n",
    "# ============================================================================\n",
    "# TIMELINE STAGES\n",
    "# ============================================================================\n",
    "\n",
    "stages <- data.frame(\n",
    "  Stage = c(\"PRE-SEED\", \"SEED\", \"FUNDING GAP\", \"EARLY\", \"GROWTH\"),\n",
    "  Start = c(0, 1.5, 3, 6, 9),\n",
    "  End = c(1.5, 3, 6, 9, 15),\n",
    "  Is_Danger = c(FALSE, FALSE, TRUE, FALSE, FALSE)\n",
    ")\n",
    "\n",
    "p_timeline <- ggplot(stages) +\n",
    "  geom_rect(aes(xmin = Start, xmax = End, ymin = 0.15, ymax = 0.85, fill = Is_Danger),\n",
    "            color = GRID_COLOR, linewidth = 0.8) +\n",
    "  geom_text(aes(x = (Start + End) / 2, y = 0.5, label = Stage),\n",
    "            color = TEXT_COLOR, fontface = \"bold\", size = 4) +\n",
    "  scale_fill_manual(values = c(\"FALSE\" = COLORS$stage_default, \"TRUE\" = COLORS$funding_gap),\n",
    "                    guide = \"none\") +\n",
    "  scale_x_continuous(limits = c(0, 15), expand = c(0.01, 0)) +\n",
    "  scale_y_continuous(limits = c(0, 1)) +\n",
    "  theme_void() +\n",
    "  theme(plot.background = element_rect(fill = BACKGROUND_COLOR, color = NA),\n",
    "        plot.margin = margin(5, 25, 0, 25))\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN SURVIVAL CURVE\n",
    "# ============================================================================\n",
    "\n",
    "# Create zone color assignment\n",
    "failure_counts <- failure_counts %>%\n",
    "  mutate(\n",
    "    zone_color = case_when(\n",
    "      survival_rate >= 80 ~ COLORS$safe_zone,\n",
    "      survival_rate >= 60 ~ COLORS$improving,\n",
    "      survival_rate >= 40 ~ COLORS$caution,\n",
    "      survival_rate >= 25 ~ COLORS$moderate_risk,\n",
    "      survival_rate >= 10 ~ COLORS$high_risk,\n",
    "      TRUE ~ COLORS$extreme_danger\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Key milestones\n",
    "milestones <- failure_counts %>%\n",
    "  filter(Years_Active %in% c(3, 5, 7))\n",
    "\n",
    "p_main <- ggplot(failure_counts, aes(x = Years_Active, y = survival_rate)) +\n",
    "  \n",
    "  # Background risk zone bands\n",
    "  annotate(\"rect\", xmin = 0, xmax = 15, ymin = 0, ymax = 10, \n",
    "           fill = COLORS$extreme_danger, alpha = 0.2) +\n",
    "  annotate(\"rect\", xmin = 0, xmax = 15, ymin = 10, ymax = 25, \n",
    "           fill = COLORS$high_risk, alpha = 0.15) +\n",
    "  annotate(\"rect\", xmin = 0, xmax = 15, ymin = 25, ymax = 40, \n",
    "           fill = COLORS$moderate_risk, alpha = 0.12) +\n",
    "  annotate(\"rect\", xmin = 0, xmax = 15, ymin = 40, ymax = 60, \n",
    "           fill = COLORS$caution, alpha = 0.10) +\n",
    "  annotate(\"rect\", xmin = 0, xmax = 15, ymin = 60, ymax = 80, \n",
    "           fill = COLORS$improving, alpha = 0.10) +\n",
    "  annotate(\"rect\", xmin = 0, xmax = 15, ymin = 80, ymax = 105, \n",
    "           fill = COLORS$safe_zone, alpha = 0.12) +\n",
    "  \n",
    "  # 50% survival line\n",
    "  geom_hline(yintercept = 50, color = \"#64748b\", linewidth = 0.8, linetype = \"dashed\") +\n",
    "  annotate(\"text\", x = 14, y = 53, label = \"50% Survival\", \n",
    "           color = \"#64748b\", size = 3.5, fontface = \"italic\", hjust = 1) +\n",
    "  \n",
    "  # Fill under curve using geom_ribbon\n",
    "  geom_ribbon(aes(ymin = 0, ymax = survival_rate, fill = zone_color), alpha = 0.5) +\n",
    "  scale_fill_identity() +\n",
    "  \n",
    "  # Step survival curve with glow\n",
    "  geom_step(color = COLORS$curve, linewidth = 4, alpha = 0.2) +\n",
    "  geom_step(color = COLORS$curve, linewidth = 2) +\n",
    "  \n",
    "  # Data points\n",
    "  geom_point(color = COLORS$curve, size = 3, stroke = 1.5) +\n",
    "  \n",
    "  # Milestone annotations\n",
    "\n",
    "  geom_segment(data = milestones, \n",
    "               aes(x = Years_Active, xend = Years_Active, y = 0, yend = survival_rate),\n",
    "               color = COLORS$milestone, linetype = \"dotted\", linewidth = 0.7, alpha = 0.7) +\n",
    "  geom_segment(data = milestones,\n",
    "               aes(x = 0, xend = Years_Active, y = survival_rate, yend = survival_rate),\n",
    "               color = COLORS$milestone, linetype = \"dotted\", linewidth = 0.7, alpha = 0.7) +\n",
    "  geom_label(data = milestones,\n",
    "             aes(x = Years_Active + 0.5, y = survival_rate + 4, \n",
    "                 label = paste0(round(survival_rate), \"%\")),\n",
    "             fill = BACKGROUND_COLOR, color = COLORS$milestone, \n",
    "             fontface = \"bold\", size = 4, label.size = 0) +\n",
    "  \n",
    "  # Valley of Death annotation\n",
    "  annotate(\"label\", x = 8, y = 35, \n",
    "           label = \"Valley of Death\\n(Peak Risk Zone)\",\n",
    "           fill = BACKGROUND_COLOR, color = COLORS$extreme_danger,\n",
    "           fontface = \"bold\", size = 4.5, label.size = 1) +\n",
    "  annotate(\"curve\", x = 7, y = 38, xend = 5.2, yend = 58,\n",
    "           curvature = 0.3, arrow = arrow(length = unit(0.2, \"cm\"), type = \"closed\"),\n",
    "           color = COLORS$extreme_danger, linewidth = 1) +\n",
    "  \n",
    "  # Scales\n",
    "  scale_x_continuous(breaks = 0:15, limits = c(0, 15), expand = c(0.02, 0)) +\n",
    "  scale_y_continuous(breaks = seq(0, 100, 20), limits = c(0, 105)) +\n",
    "  labs(x = \"Years Since Founding\", y = \"Survival Rate (%)\") +\n",
    "  theme_dark_dashboard()\n",
    "\n",
    "# ============================================================================\n",
    "# FAILURE DISTRIBUTION BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "failure_counts <- failure_counts %>%\n",
    "  mutate(\n",
    "    bar_color = case_when(\n",
    "      failure_rate >= 10 ~ COLORS$extreme_danger,\n",
    "      failure_rate >= 5 ~ COLORS$high_risk,\n",
    "      failure_rate >= 3 ~ COLORS$moderate_risk,\n",
    "      TRUE ~ COLORS$caution\n",
    "    )\n",
    "  )\n",
    "\n",
    "p_bars <- ggplot(failure_counts, aes(x = Years_Active, y = failure_rate)) +\n",
    "  geom_col(aes(fill = bar_color), width = 0.8, alpha = 0.85) +\n",
    "  scale_fill_identity() +\n",
    "  geom_text(aes(label = ifelse(failures > 0, failures, \"\")), \n",
    "            vjust = -0.5, color = TEXT_COLOR, fontface = \"bold\", size = 3) +\n",
    "  \n",
    "  # Peak annotation\n",
    "  annotate(\"text\", \n",
    "           x = failure_counts$Years_Active[which.max(failure_counts$failure_rate)] + 2,\n",
    "           y = max(failure_counts$failure_rate) + 1,\n",
    "           label = paste0(\"Peak: Year \", failure_counts$Years_Active[which.max(failure_counts$failure_rate)]),\n",
    "           color = COLORS$extreme_danger, fontface = \"bold\", size = 4) +\n",
    "  annotate(\"segment\",\n",
    "           x = failure_counts$Years_Active[which.max(failure_counts$failure_rate)] + 1.5,\n",
    "           xend = failure_counts$Years_Active[which.max(failure_counts$failure_rate)] + 0.3,\n",
    "           y = max(failure_counts$failure_rate) + 0.5,\n",
    "           yend = max(failure_counts$failure_rate) + 0.2,\n",
    "           arrow = arrow(length = unit(0.15, \"cm\"), type = \"closed\"),\n",
    "           color = COLORS$extreme_danger, linewidth = 1) +\n",
    "  \n",
    "  scale_x_continuous(breaks = 0:15, limits = c(-0.5, 15.5)) +\n",
    "  scale_y_continuous(limits = c(0, max(failure_counts$failure_rate) * 1.3)) +\n",
    "  labs(x = \"Years Since Founding\", y = \"Failure Rate (%)\",\n",
    "       title = \"Annual Failure Distribution (number of companies failing each year)\") +\n",
    "  theme_dark_dashboard() +\n",
    "  theme(plot.title = element_text(color = SUBTITLE_COLOR, size = 11, hjust = 0.5))\n",
    "\n",
    "# ============================================================================\n",
    "# LEGEND\n",
    "# ============================================================================\n",
    "\n",
    "legend_data <- data.frame(\n",
    "  x = 1:6,\n",
    "  label = c(\"<10%\\nCritical\", \"10-25%\\nDanger\", \"25-40%\\nAt Risk\",\n",
    "            \"40-60%\\nCaution\", \"60-80%\\nStable\", \">80%\\nSafe\"),\n",
    "  color = c(COLORS$extreme_danger, COLORS$high_risk, COLORS$moderate_risk,\n",
    "            COLORS$caution, COLORS$improving, COLORS$safe_zone)\n",
    ")\n",
    "\n",
    "p_legend <- ggplot(legend_data) +\n",
    "  geom_tile(aes(x = x, y = 0.5, fill = color), width = 0.9, height = 0.6) +\n",
    "  geom_text(aes(x = x, y = 0.5, label = label), \n",
    "            color = TEXT_COLOR, fontface = \"bold\", size = 3, lineheight = 0.85) +\n",
    "  scale_fill_identity() +\n",
    "  annotate(\"text\", x = 3.5, y = 1, label = \"SURVIVAL ZONES\",\n",
    "           color = SUBTITLE_COLOR, fontface = \"bold\", size = 3.5) +\n",
    "  scale_x_continuous(limits = c(0.4, 6.6)) +\n",
    "  scale_y_continuous(limits = c(0, 1.2)) +\n",
    "  theme_void() +\n",
    "  theme(plot.background = element_rect(fill = BACKGROUND_COLOR, color = NA),\n",
    "        plot.margin = margin(5, 60, 15, 60))\n",
    "\n",
    "# ============================================================================\n",
    "# COMBINE PLOTS\n",
    "# ============================================================================\n",
    "\n",
    "final_plot <- p_title / p_timeline / p_main / p_bars / p_legend +\n",
    "  plot_layout(heights = c(0.08, 0.06, 0.45, 0.3, 0.11))\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE\n",
    "# ============================================================================\n",
    "\n",
    "ggsave(\"the_valley_of_death.png\", final_plot,\n",
    "       width = 16, height = 14, dpi = 300, bg = BACKGROUND_COLOR)\n",
    "\n",
    "cat(\"\\n✓ Visualization saved!\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRINT KEY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "cat(\"\\n\", paste(rep(\"=\", 60), collapse = \"\"), \"\\n\")\n",
    "cat(\"KEY INSIGHTS FROM SURVIVAL ANALYSIS\\n\")\n",
    "cat(paste(rep(\"=\", 60), collapse = \"\"), \"\\n\")\n",
    "\n",
    "cat(\"\\n📉 Survival Milestones:\\n\")\n",
    "for(yr in c(1, 2, 3, 5, 7, 10)) {\n",
    "  surv <- failure_counts %>% filter(Years_Active == yr) %>% pull(survival_rate)\n",
    "  if(length(surv) > 0) {\n",
    "    cat(\"   After\", yr, \"year(s):\", round(surv, 1), \"% still operating\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "fifty_pct_year <- failure_counts %>% filter(survival_rate <= 50) %>% \n",
    "  slice_min(Years_Active) %>% pull(Years_Active)\n",
    "cat(\"\\n⚠️  50% of startups fail by Year\", fifty_pct_year, \"\\n\")\n",
    "\n",
    "cat(\"\\n🔥 Highest Risk Years:\\n\")\n",
    "top_years <- failure_counts %>% arrange(desc(failures)) %>% head(5)\n",
    "for(i in 1:nrow(top_years)) {\n",
    "  cat(\"   Year\", top_years$Years_Active[i], \":\", \n",
    "      top_years$failures[i], \"failures (\", round(top_years$failure_rate[i], 1), \"%)\\n\")\n",
    "}\n",
    "\n",
    "valley_failures <- failure_counts %>% \n",
    "  filter(Years_Active >= 3 & Years_Active <= 7) %>%\n",
    "  summarise(total = sum(failures)) %>% pull(total)\n",
    "cat(\"\\n🎯 Valley of Death (Years 3-7):\", valley_failures, \"failures (\",\n",
    "    round(valley_failures/total_startups*100, 1), \"% of all)\\n\")\n",
    "\n",
    "cat(paste(rep(\"=\", 60), collapse = \"\"), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Valley of Death\n",
    "Zahir Graph: Exploratory Data Analysis (EDA) An initial examination of the dataset reveals distinct distributional characteristics across the primary variables. The temporal variable, Lifespan, follows a moderately right-skewed distribution (skewness: 0.67) with a central tendency leaning towards mid-stage failure; the mean duration is 7.5 years, closely aligning with a median of 7.0 years. In contrast, the Funding variable exhibits extreme positive skewness (skewness: >10), evidenced by a massive disparity between the median raised capital ($30M) and the mean ($190M). Outlier analysis utilizing the Interquartile Range (IQR) method confirms the presence of 53 significant \"capital outliers\"—companies that raised exceptional sums exceeding the calculated upper bound of $301.25M, with the most extreme case reaching $10.4B. When investigating the relationship between these variables, the bivariate analysis uncovers a surprising disconnect: the Pearson correlation coefficient between Funding and Lifespan is a negligible 0.067. This lack of linear association suggests that capital abundance is not a reliable predictor of longevity, as confirmed by a scatter plot visualization where well-funded \"unicorns\" frequently appear in the same early-failure clusters as their leaner counterparts.\n",
    "\n",
    "Analytical Approach & Findings To rigorously evaluate the dynamics of startup mortality,  employing the Kaplan-Meier Survival Estimator, a non-parametric statistic chosen for its ability to model time-to-event probabilities and account for the cumulative risk of failure over time, which offers superior insight compared to simple average lifespans. The analysis yielded a distinct \"Valley of Death Survival Curve,\" revealing that the probability of survival undergoes a decline specifically between Years 3 and 7, dropping from a secure 92% to a precarious 42%. Year 5 was identified as the single deadliest inflection point, accounting for 18.3% of all failures. My interpretation of these findings challenges the conventional wisdom that funding is the primary safety net; instead, the data indicates that the critical \"Valley\" period represents an operational crisis where startups must transition from burning capital to proving competitive dominance. The fact that 77% of failures cited \"Competition\" as a primary cause—regardless of funding levels—suggests that market positioning, rather than bank balance, is the true determinant of survival past the seven-year mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-correlation_between_funding_outcomes_and_failure_metrics"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Correlation between Funding, Outcomes, and Failure Metrics\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Correlation between Funding, Outcomes, and Failure Metrics\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"correlation_between_funding_outcomes_and_failure_metrics.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between Funding, Outcomes, and Failure Metrics\n",
    "\n",
    "Yasir Graph (Correlation Heatmap) : Our correlation heatmap brings out the various interesting links that exist between funding attributes and the probability or timing of success or failure for the startup. One of the interesting links in the graphical representation is the association between “Has VC” and “Age at Last Funding.” This suggests that the probability of being funded by VCs means the startup stays in business for longer periods and generates more funding throughout the life span. Thus, being backed by VCs allows the startup to stay in business for more years before experiencing the end event of failure. Although, the heatmap displays that likelihood of being acquired is more deeply influenced with later stage funding rounds (Series A - D) rather than solely being associated with having VC, as the funding rounds show the stronger correlations with the “Status” variable. However, the link between “Has Angel” and “Age of Last Funding” & “Age of Last Milestone” suggests an inverse association and suggests that the startup funded by an angel achieves its funding milestone in its existence sooner. Thus, the startup stays for the same duration before being acquired or experiencing failure. However, the association in the graphical representation suggests that the startup backed by VCs stays longer in business.\n",
    "\n",
    "Another key takeaway is the significance of having “# Relationships” related to the funding in the later stages. Startups backed by Series B, C, D funding exhibit one of the top positive values for their numbers of partnerships and connections. This serves to highlight the point that advanced funding levels might correlate to having larger networks. Early funding-restricted companies (those that lack access to funding in the later stages but are in the early stage) fare poorly in building relationships. This goes to imply that their life span might be shorter. However, the correlation value between milestone timing and Series A-D funding turns out to be higher compared to the years of the span of the company. So, the advancement within the company might play an important part rather than the life span of the business indicated by the later funding milestones. Interestingly, the correlation between “Total Raised (USD)” and outcome/operational metrics appears to be rather weak, suggesting that the level of capital raised does not play a significant part in influencing the failure and acquisition of the startup. However, the correlative analysis of the heatmap appears to suggest that the level of funding (level of VC commitment or advancement from Series A through D funding, as explained previously) is rather influential in the determination of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-funding_vs_years_operated"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Funding vs Years Operated\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Funding vs Years Operated\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"funding_vs_years_operated.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funding vs Years Operated\n",
    "Adam Graph (2D Scatter-Plot): The scatter plot above shows a poor relationship between how much funding a startup gets and how long they have been operating for. While there is a larger spread and greater variance for some older startups, (typically around 6- 15 years) there is not a reliable trend that shows that as the company ages, funding gets increased as a result. When looking at the data, it seems that the sector of the startup has higher influence than the years it has been active for. The FinTech, Social Media, and HealthTech sectors all consistently attract high funding, while sectors such as Gaming, E-commerce, and FoodTech attract lower amounts of funding apart from a few exceptions. This indicates that sector choice is a higher indicator of funding size than company age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "r",
    "name": "r-acquired_vs_closed_startups_on_key_funding_metrics"
   },
   "outputs": [],
   "source": [
    "# To use with rpy2, add %%R as the first line\n",
    "# %%R\n",
    "\n",
    "# Acquired vs Closed Startups on Key Funding Metrics\n",
    "# R code for generating the visualization\n",
    "# Replace this with your actual R code from your .RMD file\n",
    "\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "# Add other required libraries here\n",
    "\n",
    "# Load data\n",
    "# dataset1_df <- read.csv(\"data/02-processed/dataset1_cleaned.csv\")\n",
    "# dataset2_df <- read.csv(\"data/02-processed/CleanData2.csv\")\n",
    "# Add your data loading code here\n",
    "\n",
    "# Create visualization\n",
    "# Add your R plotting code here\n",
    "# Example structure:\n",
    "# ggplot(data, aes(x = ..., y = ...)) +\n",
    "#   geom_...() +\n",
    "#   labs(title = \"Acquired vs Closed Startups on Key Funding Metrics\") +\n",
    "#   theme_...()\n",
    "\n",
    "# Save plot (optional)\n",
    "# ggsave(\"acquired_vs_closed_startups_on_key_funding_metrics.png\", width = 10, height = 6, dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquired vs Closed Startups on Key Funding Metrics\n",
    "Mostafa: The graphs above compare startup funding amounts, number of funding rounds, and the final company outcomes between acquired and closed startups. A boxplot was ideal because it was the cleanest way of comparing medians and variability with skewed data that contained a lot of outliers. A log_10 transformation was applied to the values to compress the scale for clarity because of how wide the range of funding spans were. \n",
    "\n",
    "Total Funding is very right skewed and follows a log normal shape. Funding rounds are discrete, moderately skewed and most companies are between 1-5 rounds. Funding per round is very skewed because of differences in round sizes (log_10 was used to normalize it).\n",
    "\n",
    "All three variables contain extreme outliers, especially in total funding. Funding rounds shows a positive nonlinear relationship, where companies raising more rounds tend to secure higher total funding. Funding per round is weakly correlated with the outcome, where sustained fundraising momentum matters more than single round funds. \n",
    "\n",
    "\n",
    "The results reveal a few somewhat surprising patterns; while it’s expected that acquired startups do typically raise more total funding and have more rounds, it’s only modestly higher, which suggests that sustained investor support (more rounds over time) matters more than the size of the check. Many closed startups raised very large amounts of money, often exceeding the levels of acquired firms, which shows that high funding doesn’t guarantee success. Additionally the distributions for acquired and closed companies overlap heavily in early stages, which tells us that early performance isn’t predictive and that meaningful divergence only appears after multiple rounds. These insights highlight that long term fundraising momentum, not early funding levels is the strongest signal correlated with eventual acquisition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bias & fairness:** Datasets may favor startups or sectors that are much higher in popularity and show a bias towards well known startups. There are also concerns with issues of generlzation as some areas may have high density of startups compared to others potential misrepresenting the data.\n",
    "- **Generalization limits:** As mentioned previously, Kaggle datasets in particular may overrepresent high success startups due to the ease of accessing the data. This results in the data not geenrlazaing to non-tech or smaller companies. We intend to avoid general claims and make specifc statements that are contextualized by environment maturity.\n",
    "- **Data sensitivity:** Although the data gathered is public, names and emails can be used to reidenifty an individual, or any specific data points that can be used to triangulate a person or startup. \n",
    "- **Non-Consensual Use of Company Information:** Despite the data being public, startups in the dataset did not consent to be analyzed or used for prediction exercises. We will be using aggregated analysis and not single out any companies.\n",
    "- **Potential Misrepresentation Due to Inaccurate or Incomplete Data:** Startup databases are often incomplete, outdated, or wrong because the data is crowdsourced. We will treat the data as approximate and emphasize uncertainty rather than presenting results as definitive truth.\n",
    "- **Responsibility to Prevent Harmful Use of Results:** If someone misuses the findings it may influence funding or hiring decisions, or perceptions of certain industries/regions. We will explicitly state that the work should not be used for investment decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regards to communication, we plan on using iMessage to text one another. We believe this is one of the most efficient and easiest ways for us to contact one another. As for the ,essaging itself, all members have agreed to expect a rresponse, whether that be a message or a reaction, from each group member within 3 hours of the initial text being sent. We will meet twice per week, every Monday morning we will reserve a study space in the Geisel Library to meet and prodvide updates, followed by a Zoom meetimng every Friday afternoon to consolidate the designated progress from Onday's meeting. In regarcs to tone, we agree to all expect respectful interactions. Even when disagreement takes place, the person expressing the lack of approval should explain their reasonibg, as well as an alkternative method that they beleive is better. We will be concise and to the point, but still maintaining respect for one another and everyone's ideas. We plan to use voting to make decisions as a group, especially for disagreements and changes to our original plan. The project administrator will be in charge of calling teh vote, ad we will go with the majority ruling, as wel have3 5 people. We will not accept abstaining from votes. We do have specialized roles for each person, hwoever, because there is overlap, we do plan to share a lot of the responsibilties. As we are a team, we plan on heloing each other out when possible, especially if one person is struggling with a specific task. We assign roles and tasks based on the skillsets of the members, which we have laready discussed in detail. We have set a policy that struggles are inevitbale, as we are all busy. We have a guideline that whenever someone is falling behind, there is no hassle or problem in expressing that as early as possible. We would rather know what to fix earlier on in the process, rather than have a last minute lack of execution. Struggles with certain tasks hoild be expressd immediately, as we will set egos aside ti help regardless of role/assignned tasks, in roder to priotitize the team as a unit/whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline\n",
    "### Week 3\n",
    "- **Monday:** Meeting to brainstorm project topics, confirm individual dataset search responsibilities and initiate the plan for our topic.\n",
    "- **Friday:** Zoom meeting to vote on and finalize topic.,\n",
    "- **Sunday:** Zoom meeting to discuss roles then consolidate and review the datasets we’ve individually found.\n",
    "\n",
    "### Week 4\n",
    "- **Monday:** Meet in Geisel to consolidate datasets and assign roles for our project proposal. Begin working on data cleaning plan, early transformations, and outline visualization goals.\n",
    "- **Wednesday:** Proofread and finalize proposal\n",
    "\n",
    "\n",
    "### Week 5,\n",
    "- **Monday:** Begin data cleaning and preprocessing our datasets.\n",
    "- **Wednesday:** Continue data cleaning and finalize our structured and processed dataset; share cleaned files with each other.\n",
    "\n",
    "### Week 6\n",
    "- **Sunday:** Zoom meeting to compare our processed datasets and make sure everything is consistent.\n",
    "- **Monday:** Discuss trends and finalize consensus on dataset selection and structure.\n",
    "- **Wednesday:** Complete initial EDA preparation, finalize plan for visualization types.\n",
    "\n",
    "### Week 7\n",
    "- **Monday:** Start building visualizations, assign figure responsibilities to group members.\n",
    "- **Friday:** Review meeting to make sure visualizations are progressing and discuss results and narrative.\n",
    "\n",
    "### Week 8\n",
    "- **Monday:** Compile all visualizations and ensure consistency.\n",
    "- **Wednesday:** Polish everything, ensure code runs cleanly.\n",
    "\n",
    "### Week 9\n",
    "- **Monday:** Final review session, proofread notebook text, verify rubric requirements, and finalize project. Begin preparing video.\n",
    "- **Wednesday:** Submit final project and recording; complete team evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}